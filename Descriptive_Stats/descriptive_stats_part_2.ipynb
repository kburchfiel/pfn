{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae086d03-43a3-432e-a7bf-a289e4f0f365",
   "metadata": {},
   "source": [
    "# Descriptive Stats: Part 2\n",
    "\n",
    "By Kenneth Burchfiel \n",
    "\n",
    "Released under the MIT license\n",
    "\n",
    "This second part of Python for Nonprofits' descriptive stats section covers several potential data analysis pitfalls. Specifically, it will explore:\n",
    "\n",
    "1. Challenges with finding average values for tables whose rows are themselves averages\n",
    "2. Methods of accounting for missing data when creating pivot tables\n",
    "3. Issues with using `np.where()` to create derivatives of columns with missing data (and why `map()` and `np.select()` are better fits)\n",
    "\n",
    "I have to admit that, even by programming textbook standards, you may not find this to be the most exciting chapter. You may well be anxious to get ahead to the graphing, mapping, and online dashboard sections of PFN (which are just around the corner). \n",
    "\n",
    "However, in order to be confident that your graphs, maps, and dashboards will provide an accurate view of your underlying data, it's crucial to exercise caution when pivoting and transforming tables. This chapter is meant to help you be more cautious--and thus more successful--in your data analysis adventures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98e1126f-9ae5-421d-b500-7114d1ebe2aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T02:04:54.601029Z",
     "iopub.status.busy": "2025-02-25T02:04:54.600928Z",
     "iopub.status.idle": "2025-02-25T02:04:54.836799Z",
     "shell.execute_reply": "2025-02-25T02:04:54.836519Z",
     "shell.execute_reply.started": "2025-02-25T02:04:54.601017Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "e = create_engine('sqlite:///../Appendix/nvcu_db.db')\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../Appendix')\n",
    "from helper_funcs import config_notebook\n",
    "display_type = config_notebook(display_max_columns = 5,\n",
    "                              display_max_rows = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcde4e40-47ef-412c-b80f-a9c67ec3de99",
   "metadata": {},
   "source": [
    "## Microdata, pre-baked data, and the 'average of averages' problem\n",
    "\n",
    "df_transactions, a table of dining hall transactions shown below, is an excellent candidate for creating a diverse set of pivot tables and charts because each transaction has its own row. (In other words, the table contains *microdata*; for more on this subject, reference https://en.wikipedia.org/wiki/Microdata_(statistics).) This allows you to calculate statistics for an arbitrary set of comparison variables by applying an aggregate function to all rows contained within those groups in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34d86f85-0c95-4f21-a4c6-45460242eb97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T02:04:54.837519Z",
     "iopub.status.busy": "2025-02-25T02:04:54.837117Z",
     "iopub.status.idle": "2025-02-25T02:04:54.871439Z",
     "shell.execute_reply": "2025-02-25T02:04:54.871099Z",
     "shell.execute_reply.started": "2025-02-25T02:04:54.837508Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starting_year</th>\n",
       "      <th>weekday</th>\n",
       "      <th>level</th>\n",
       "      <th>amount</th>\n",
       "      <th>transactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>We</td>\n",
       "      <td>Fr</td>\n",
       "      <td>13.36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>Tu</td>\n",
       "      <td>Se</td>\n",
       "      <td>12.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>We</td>\n",
       "      <td>Se</td>\n",
       "      <td>23.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>Su</td>\n",
       "      <td>Fr</td>\n",
       "      <td>18.78</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023</td>\n",
       "      <td>Tu</td>\n",
       "      <td>Fr</td>\n",
       "      <td>11.36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   starting_year weekday level  amount  transactions\n",
       "0           2023      We    Fr   13.36             1\n",
       "1           2023      Tu    Se   12.22             1\n",
       "2           2023      We    Se   23.10             1\n",
       "3           2023      Su    Fr   18.78             1\n",
       "4           2023      Tu    Fr   11.36             1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions = pd.read_sql(\n",
    "    'select * from dining_transactions', con = e)\n",
    "df_transactions['transactions'] = 1\n",
    "df_transactions.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1c29e0-0c86-49bf-9857-55ec43439bcb",
   "metadata": {},
   "source": [
    "If you wanted to calculate the average dining hall transaction amount, you could simply find the mean of all items within this table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08e5f2e1-bd87-407a-a5b8-a83553f8d051",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T02:04:54.872298Z",
     "iopub.status.busy": "2025-02-25T02:04:54.872175Z",
     "iopub.status.idle": "2025-02-25T02:04:54.874875Z",
     "shell.execute_reply": "2025-02-25T02:04:54.874624Z",
     "shell.execute_reply.started": "2025-02-25T02:04:54.872287Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(12.65563577250256)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions['amount'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7193e8f0-cdce-413f-a173-f8d6daea647c",
   "metadata": {},
   "source": [
    "If you instead wanted to find the average amount spent by *weekday and level*, you could easily do so via pandas' `pivot_table()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "368f34e4-2ccb-46f3-b62d-0fbffa150ad1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T02:04:54.875279Z",
     "iopub.status.busy": "2025-02-25T02:04:54.875175Z",
     "iopub.status.idle": "2025-02-25T02:04:54.885588Z",
     "shell.execute_reply": "2025-02-25T02:04:54.885320Z",
     "shell.execute_reply.started": "2025-02-25T02:04:54.875270Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekday</th>\n",
       "      <th>level</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Su</td>\n",
       "      <td>Se</td>\n",
       "      <td>22.426887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>We</td>\n",
       "      <td>Se</td>\n",
       "      <td>21.550155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mo</td>\n",
       "      <td>Se</td>\n",
       "      <td>21.346364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Tu</td>\n",
       "      <td>Se</td>\n",
       "      <td>21.268938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>We</td>\n",
       "      <td>Fr</td>\n",
       "      <td>9.916478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Tu</td>\n",
       "      <td>Fr</td>\n",
       "      <td>9.835650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Su</td>\n",
       "      <td>Fr</td>\n",
       "      <td>9.812551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sa</td>\n",
       "      <td>Fr</td>\n",
       "      <td>9.467975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   weekday level     amount\n",
       "14      Su    Se  22.426887\n",
       "26      We    Se  21.550155\n",
       "6       Mo    Se  21.346364\n",
       "22      Tu    Se  21.268938\n",
       "..     ...   ...        ...\n",
       "24      We    Fr   9.916478\n",
       "20      Tu    Fr   9.835650\n",
       "12      Su    Fr   9.812551\n",
       "8       Sa    Fr   9.467975\n",
       "\n",
       "[28 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions.pivot_table(\n",
    "    index = ['weekday', 'level'], values = 'amount', \n",
    "    aggfunc = 'mean').reset_index().sort_values(\n",
    "    by = 'amount', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddfd5d6-1f5b-4928-850c-aa4cf14c5e97",
   "metadata": {},
   "source": [
    "However, you may not always have access to this type of data. Instead, you might receive an *aggregated* dataset in which averages by different groups are *pre-baked*--e.g. already present in the output. As you'll soon see, this makes the table much less flexible.\n",
    "\n",
    "'pre-baked' is not, to my knowledge, a common statistical term, but I find that it works pretty well for describing this type of data. For instance, once you've *baked* apples, wheat, and sugar (or whatever goes into a pie--I'm not a baker!) into a pie, it's pretty hard to convert that dish into a caramelized apple. Similarly, as the following examples will show, once you've 'baked' a list of transactions into separate sets of averages by level and by weekday, it will be impossible to use that data to calculate total spending amounts by level *and* weekday--as we no longer know how each level value relates to each weekday value.\n",
    "\n",
    "To illustrate this issues caused by pre-baked datasets, let's generate two DataFrames, the first of which will show average transaction amounts by level, and the second of which will show average amounts by weekday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23024958-78ae-4a1d-aaae-d8d9240a4084",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T02:04:54.886082Z",
     "iopub.status.busy": "2025-02-25T02:04:54.885947Z",
     "iopub.status.idle": "2025-02-25T02:04:54.893189Z",
     "shell.execute_reply": "2025-02-25T02:04:54.892959Z",
     "shell.execute_reply.started": "2025-02-25T02:04:54.886072Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>amount</th>\n",
       "      <th>transactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fr</td>\n",
       "      <td>9.911620</td>\n",
       "      <td>12410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ju</td>\n",
       "      <td>17.133287</td>\n",
       "      <td>3289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Se</td>\n",
       "      <td>21.294252</td>\n",
       "      <td>2046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So</td>\n",
       "      <td>13.006451</td>\n",
       "      <td>4708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  level     amount  transactions\n",
       "0    Fr   9.911620         12410\n",
       "1    Ju  17.133287          3289\n",
       "2    Se  21.294252          2046\n",
       "3    So  13.006451          4708"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_average_spending_by_level = df_transactions.pivot_table(\n",
    "    index = 'level', values = [\n",
    "    'amount', 'transactions'], aggfunc = {\n",
    "    'amount':'mean', 'transactions':'count'}).reset_index()\n",
    "df_average_spending_by_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfc5f9b9-0eee-416d-8cf8-51681e1445da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T02:04:54.893623Z",
     "iopub.status.busy": "2025-02-25T02:04:54.893514Z",
     "iopub.status.idle": "2025-02-25T02:04:54.900450Z",
     "shell.execute_reply": "2025-02-25T02:04:54.900184Z",
     "shell.execute_reply.started": "2025-02-25T02:04:54.893613Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekday</th>\n",
       "      <th>amount</th>\n",
       "      <th>transactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fr</td>\n",
       "      <td>12.721265</td>\n",
       "      <td>2466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mo</td>\n",
       "      <td>12.632190</td>\n",
       "      <td>3608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sa</td>\n",
       "      <td>12.253912</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Su</td>\n",
       "      <td>12.775699</td>\n",
       "      <td>1123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Th</td>\n",
       "      <td>12.592931</td>\n",
       "      <td>3964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tu</td>\n",
       "      <td>12.747500</td>\n",
       "      <td>5267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>We</td>\n",
       "      <td>12.624990</td>\n",
       "      <td>5317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  weekday     amount  transactions\n",
       "0      Fr  12.721265          2466\n",
       "1      Mo  12.632190          3608\n",
       "2      Sa  12.253912           708\n",
       "3      Su  12.775699          1123\n",
       "4      Th  12.592931          3964\n",
       "5      Tu  12.747500          5267\n",
       "6      We  12.624990          5317"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_average_spending_by_weekday = df_transactions.pivot_table(\n",
    "    index = 'weekday', values = [\n",
    "    'amount', 'transactions'], aggfunc = {\n",
    "    'amount':'mean', 'transactions':'count'}).reset_index()\n",
    "df_average_spending_by_weekday"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb413868-ae05-4c14-a63a-d7d5100de2fb",
   "metadata": {},
   "source": [
    "We can see that lower levels (e.g. freshmen and sophomores) tend to spend more per dining hall visit than upper levels; in addition, we can see that spending is relatively constant across weekdays. However, because these tables are pre-baked, we don't have any way of calculating average spending by level *and* weekday like we could with df_transactions. \n",
    "\n",
    "In addition, let's say that we wanted to calculate average dining hall spending using df_average_spending_by_level. A naive approach would be to simply calculate the average of each row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da2dd436-c873-47b7-88b4-9d67b2384dd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T02:04:54.900907Z",
     "iopub.status.busy": "2025-02-25T02:04:54.900792Z",
     "iopub.status.idle": "2025-02-25T02:04:54.903077Z",
     "shell.execute_reply": "2025-02-25T02:04:54.902853Z",
     "shell.execute_reply.started": "2025-02-25T02:04:54.900897Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(15.336402324109617)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following approach is incorrect!\n",
    "\n",
    "df_average_spending_by_level['amount'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886f2e7f-c9ca-44e4-b28e-c797f9e10cf6",
   "metadata": {},
   "source": [
    "This average is way off the actual average, which we calculated earlier in this code using df_transactions. Why is this the case? As df_average_spending_by_level shows, seniors and juniors spend much more than freshmen and sophomores, yet they also use the dining hall less (as shown by their smaller transaction counts). As a result, if we simply average the mean transaction amounts for each level, we'll overrepresent upperclassmen and thus skew our average transaction amount upward.\n",
    "\n",
    "In order to avoid this 'average of averages' issue, which arises whenever differences in group sizes skew an average that's in turn based on averages for those groups, we'll need to create a *weighted* average. We can do so by multiplying each row's 'amount' column by its 'transaction' column; adding these products together; and then dividing them by the 'transaction' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75a905ac-fa83-4fa0-8590-fa165477e07d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T02:04:54.903462Z",
     "iopub.status.busy": "2025-02-25T02:04:54.903365Z",
     "iopub.status.idle": "2025-02-25T02:04:54.907505Z",
     "shell.execute_reply": "2025-02-25T02:04:54.907281Z",
     "shell.execute_reply.started": "2025-02-25T02:04:54.903453Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>amount</th>\n",
       "      <th>transactions</th>\n",
       "      <th>amount_x_transactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fr</td>\n",
       "      <td>9.911620</td>\n",
       "      <td>12410</td>\n",
       "      <td>123003.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ju</td>\n",
       "      <td>17.133287</td>\n",
       "      <td>3289</td>\n",
       "      <td>56351.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Se</td>\n",
       "      <td>21.294252</td>\n",
       "      <td>2046</td>\n",
       "      <td>43568.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So</td>\n",
       "      <td>13.006451</td>\n",
       "      <td>4708</td>\n",
       "      <td>61234.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  level     amount  transactions  amount_x_transactions\n",
       "0    Fr   9.911620         12410              123003.20\n",
       "1    Ju  17.133287          3289               56351.38\n",
       "2    Se  21.294252          2046               43568.04\n",
       "3    So  13.006451          4708               61234.37"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_average_spending_by_level['amount_x_transactions'] = (\n",
    "    df_average_spending_by_level['amount'] \n",
    "    * df_average_spending_by_level['transactions'])\n",
    "df_average_spending_by_level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddac54da-87b4-49ee-b059-e6866e04f82f",
   "metadata": {},
   "source": [
    "Here's our weighted average, which matches the average calculated earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "917ba5f3-7f66-42c6-8839-d8054f1129e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T02:04:54.907886Z",
     "iopub.status.busy": "2025-02-25T02:04:54.907791Z",
     "iopub.status.idle": "2025-02-25T02:04:54.911299Z",
     "shell.execute_reply": "2025-02-25T02:04:54.911018Z",
     "shell.execute_reply.started": "2025-02-25T02:04:54.907876Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(12.65563577250256)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_average_spending_by_level['amount_x_transactions'].sum() \n",
    " / df_average_spending_by_level['transactions'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f6cddb-f361-47d8-b14c-d00bde395538",
   "metadata": {},
   "source": [
    "The following function can be used to calculate weighted means for other datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c82203e-46d8-471b-89cd-4f70c495638e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T02:04:54.911717Z",
     "iopub.status.busy": "2025-02-25T02:04:54.911615Z",
     "iopub.status.idle": "2025-02-25T02:04:54.916371Z",
     "shell.execute_reply": "2025-02-25T02:04:54.916104Z",
     "shell.execute_reply.started": "2025-02-25T02:04:54.911707Z"
    }
   },
   "outputs": [],
   "source": [
    "def weighted_mean(original_df, metric_col, weight_col):\n",
    "    '''This function calculates, then returns, a weighted mean for\n",
    "    the DataFrame passed to original_df.\n",
    "    metric_col: the column storing the variable for which to calculate\n",
    "    a mean.\n",
    "    weight_col: the column storing weight values that will be incorporated\n",
    "    into this weighted mean.    \n",
    "    '''\n",
    "    df = original_df.copy() # Prevents the function from modifying\n",
    "    # the original DataFrame\n",
    "    df['metric_x_weight'] = df[metric_col] * df[weight_col]\n",
    "    weighted_mean = (df['metric_x_weight'].sum() / \n",
    "    df[weight_col].sum())\n",
    "    return weighted_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b645bc6-5d68-45ba-85c6-378a4ce96e1b",
   "metadata": {},
   "source": [
    "Let's try putting this function into action by calculating the average transaction amount using df_average_spending_by_weekday:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31f5f212-ca5b-414e-9021-a73afc7ca11d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T02:04:54.916783Z",
     "iopub.status.busy": "2025-02-25T02:04:54.916680Z",
     "iopub.status.idle": "2025-02-25T02:04:54.920629Z",
     "shell.execute_reply": "2025-02-25T02:04:54.920408Z",
     "shell.execute_reply.started": "2025-02-25T02:04:54.916773Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(12.65563577250256)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_mean(df_average_spending_by_weekday, \n",
    "                 metric_col = 'amount',\n",
    "                 weight_col = 'transactions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6803eb-acd8-4e7a-a2f6-31cdc8266940",
   "metadata": {},
   "source": [
    "This average matches the weighted average that we calculated within df_average_spending_by_level. \n",
    "\n",
    "Incidentally, because average transaction amounts are relatively constant across weekdays, simply averaging all 'amount' values within df_average_spending_by_weekday will get us very close to the actual average (despite the considerable variation in transaction counts by weekday). These kinds of 'believable', yet incorrect values are particularly insidious: they may go unnoticed for quite a while, whereas an obviously incorrect value (e.g. a calculated mean transaction of -5, or 83,000) would get caught right away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "951738c3-38d5-4216-beb9-487bfba8c02b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T02:04:54.922010Z",
     "iopub.status.busy": "2025-02-25T02:04:54.921899Z",
     "iopub.status.idle": "2025-02-25T02:04:54.924196Z",
     "shell.execute_reply": "2025-02-25T02:04:54.923961Z",
     "shell.execute_reply.started": "2025-02-25T02:04:54.922001Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(12.621212399856491)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_average_spending_by_weekday['amount'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ef2d30-2564-48bd-be4d-e6df890f03d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T03:01:34.093172Z",
     "iopub.status.busy": "2025-01-22T03:01:34.091840Z",
     "iopub.status.idle": "2025-01-22T03:01:34.097099Z",
     "shell.execute_reply": "2025-01-22T03:01:34.096691Z",
     "shell.execute_reply.started": "2025-01-22T03:01:34.093107Z"
    }
   },
   "source": [
    "We were able to calculate correct averages within these pre-baked tables because we also knew the number of transactions within each row. In the real world, though, such sample size information may not be available.\n",
    "\n",
    "From a data analysis perspective, it would be ideal to have all of your source data in microdata (rather than pre-baked) form. However, the microdata approach has its own drawbacks. \n",
    "\n",
    "First, data privacy needs may preclude the issuance of microdata. Imagine, for instance, that NVCU released a dataset that contained individual course grades for each student along with those students' ages and majors. If you happened to be the only 18-year-old music major who took a course, anyone with that knowledge could find out how you performed in the class. \n",
    "\n",
    "A more private approach, in this case, would be to release separate 'pre-baked' tables that showed average grades by age and by major. (Even with this strategy, if a given pre-baked average was based on only a few students, it might be best to remove that row's data so as to protect those students' privacy.)\n",
    "\n",
    "Second, microdata can take up much more storage size than pre-baked data. To illustrate this, let's compare the amount of memory, in kilobytes, used by df_transactions (a microdata-based table) with that used by our two pre-baked tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4123e936-36fb-45c6-aa29-db443f6f952b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T02:04:54.924568Z",
     "iopub.status.busy": "2025-02-25T02:04:54.924476Z",
     "iopub.status.idle": "2025-02-25T02:04:54.932406Z",
     "shell.execute_reply": "2025-02-25T02:04:54.932160Z",
     "shell.execute_reply.started": "2025-02-25T02:04:54.924560Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2829.21)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "microdata_kb = df_transactions.memory_usage(\n",
    "    index = True, deep = True).sum() / 1000\n",
    "microdata_kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9d74ff0-506d-4716-8837-7c9e99e67aa9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T02:04:54.932810Z",
     "iopub.status.busy": "2025-02-25T02:04:54.932702Z",
     "iopub.status.idle": "2025-02-25T02:04:54.936084Z",
     "shell.execute_reply": "2025-02-25T02:04:54.935870Z",
     "shell.execute_reply.started": "2025-02-25T02:04:54.932800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.033)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_baked_kb = (df_average_spending_by_level.memory_usage(\n",
    "    index = True, deep = True).sum() + \n",
    " df_average_spending_by_weekday.memory_usage(\n",
    "    index = True, deep = True).sum()) / 1000\n",
    "pre_baked_kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7a01c77-022d-4779-948e-26ed56f329b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T02:04:54.936468Z",
     "iopub.status.busy": "2025-02-25T02:04:54.936374Z",
     "iopub.status.idle": "2025-02-25T02:04:54.938634Z",
     "shell.execute_reply": "2025-02-25T02:04:54.938422Z",
     "shell.execute_reply.started": "2025-02-25T02:04:54.936459Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2738.828654404647)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "microdata_kb / pre_baked_kb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08aee637-7439-4ab3-b3f3-2e1d1a667f37",
   "metadata": {},
   "source": [
    "The microdata table takes up over 2,700 times more memory than our two pre-baked tables! Therefore, it's understandable that data providers may prefer to share pre-calculated averages as opposed to original datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3e7992-68e8-4712-87ff-2a79413e8e23",
   "metadata": {},
   "source": [
    "## Handling missing data when creating pivot tables\n",
    "\n",
    "If a field passed to the `index` or `columns` argument of a pivot_table() call has a missing value, that missing value won't get incorporated into the final table. This can cause calculation errors if you end up using the pivot table for further analyses. However, mitigating this issue isn't too difficult.\n",
    "\n",
    "To demonstrate this issue, I'll create a 'faulty' version of df_transactions in the following cell that has `np.nan` (e.g. missing) entries for all 'Wednesday' weekday values and all 'So' level values. As you'll see, these missing values will cause issues when we (1) create a pivot table of this data, then (2) attempt to use that pivot table to determine the sum of all transactions in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29bed734-b8c3-434c-bacd-3b697be53be8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T02:04:54.939002Z",
     "iopub.status.busy": "2025-02-25T02:04:54.938909Z",
     "iopub.status.idle": "2025-02-25T02:04:54.947516Z",
     "shell.execute_reply": "2025-02-25T02:04:54.947278Z",
     "shell.execute_reply.started": "2025-02-25T02:04:54.938993Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starting_year</th>\n",
       "      <th>weekday</th>\n",
       "      <th>level</th>\n",
       "      <th>amount</th>\n",
       "      <th>transactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fr</td>\n",
       "      <td>13.36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>Tu</td>\n",
       "      <td>Se</td>\n",
       "      <td>12.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Se</td>\n",
       "      <td>23.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>Su</td>\n",
       "      <td>Fr</td>\n",
       "      <td>18.78</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22449</th>\n",
       "      <td>2023</td>\n",
       "      <td>Tu</td>\n",
       "      <td>Fr</td>\n",
       "      <td>5.98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22450</th>\n",
       "      <td>2023</td>\n",
       "      <td>Fr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22451</th>\n",
       "      <td>2023</td>\n",
       "      <td>Sa</td>\n",
       "      <td>Fr</td>\n",
       "      <td>13.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22452</th>\n",
       "      <td>2023</td>\n",
       "      <td>Mo</td>\n",
       "      <td>Fr</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22453 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       starting_year weekday level  amount  transactions\n",
       "0               2023     NaN    Fr   13.36             1\n",
       "1               2023      Tu    Se   12.22             1\n",
       "2               2023     NaN    Se   23.10             1\n",
       "3               2023      Su    Fr   18.78             1\n",
       "...              ...     ...   ...     ...           ...\n",
       "22449           2023      Tu    Fr    5.98             1\n",
       "22450           2023      Fr   NaN    7.39             1\n",
       "22451           2023      Sa    Fr   13.25             1\n",
       "22452           2023      Mo    Fr    1.95             1\n",
       "\n",
       "[22453 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions_faulty = df_transactions.copy()\n",
    "df_transactions_faulty['weekday'] = np.where(\n",
    "    df_transactions_faulty['weekday'] == 'We', \n",
    "np.nan, df_transactions_faulty['weekday']) \n",
    "df_transactions_faulty['level'] = np.where(\n",
    "    df_transactions_faulty['level'] == 'So', \n",
    "np.nan, df_transactions_faulty['level']) \n",
    "\n",
    "df_transactions_faulty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81b022a-b7a0-40f8-a705-01be2f170288",
   "metadata": {},
   "source": [
    "First, let's try converting this dataset into a pivot table that shows total transaction amounts by week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "caf1f04c-d0fa-4027-9f07-828c6d073049",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T02:04:54.947971Z",
     "iopub.status.busy": "2025-02-25T02:04:54.947839Z",
     "iopub.status.idle": "2025-02-25T02:04:54.954683Z",
     "shell.execute_reply": "2025-02-25T02:04:54.954442Z",
     "shell.execute_reply.started": "2025-02-25T02:04:54.947961Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekday</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fr</td>\n",
       "      <td>31370.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mo</td>\n",
       "      <td>45576.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sa</td>\n",
       "      <td>8675.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Su</td>\n",
       "      <td>14347.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Th</td>\n",
       "      <td>49918.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tu</td>\n",
       "      <td>67141.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  weekday    amount\n",
       "0      Fr  31370.64\n",
       "1      Mo  45576.94\n",
       "2      Sa   8675.77\n",
       "3      Su  14347.11\n",
       "4      Th  49918.38\n",
       "5      Tu  67141.08"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions_faulty_pivot = df_transactions_faulty.pivot_table(\n",
    "    index = 'weekday', values = 'amount', \n",
    "    aggfunc = 'sum').reset_index()\n",
    "df_transactions_faulty_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d10d2a-69e4-4b2b-81ec-446f37cfd7fd",
   "metadata": {},
   "source": [
    "There's no sign whatsoever of the 'Wednesday' rows. This shouldn't be too surprising (since we removed those 'We' values), but it's worth highlighting that no 'Missing' or 'N/A' row gets returned by the pivot table function.\n",
    "\n",
    "The complete absence of the 'Wednesday' row makes this this missing data issue easier to identify. However, many cases of missing data are far more insidious. For instance, suppose only a handful of 'Wednesday' entries were missing. We'd see a 'Wednesday' row within the pivot table, but we might not realize that its 'amount' sum was incorrect. (For this reason, it's often a good idea to check for missing entries within any fields that you pass to the `index` or `column` arguments of a `pivot_table()` call.)\n",
    "\n",
    "If we try to use this pivot table to calculate the sum of all our transactions, we'll end up with an incorrect result, since rows with missing 'weekday' values won't factor into the calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d8c0504-b042-443f-8273-4ae074889199",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T02:04:54.955105Z",
     "iopub.status.busy": "2025-02-25T02:04:54.954991Z",
     "iopub.status.idle": "2025-02-25T02:04:54.957294Z",
     "shell.execute_reply": "2025-02-25T02:04:54.957065Z",
     "shell.execute_reply.started": "2025-02-25T02:04:54.955094Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(217029.91999999998)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions_faulty_pivot['amount'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dcac59-aa4c-49b6-9aab-c8f208db1b36",
   "metadata": {},
   "source": [
    "For reference, here's the correct sum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "709b8620-2cd3-495e-b714-6d18a48da4f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T02:04:54.957769Z",
     "iopub.status.busy": "2025-02-25T02:04:54.957584Z",
     "iopub.status.idle": "2025-02-25T02:04:54.960008Z",
     "shell.execute_reply": "2025-02-25T02:04:54.959786Z",
     "shell.execute_reply.started": "2025-02-25T02:04:54.957753Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(284156.99)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions['amount'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cb9f25-cd25-442f-b3ee-5b8c180f1148",
   "metadata": {},
   "source": [
    "Thankfully, it's not too hard to prevent this issue. We simply need to fill in missing values within any fields fields passed to the `index` or `columns` arguments of the `pivot_table()` call.\n",
    "\n",
    "I'll demonstrate two ways to replace these values with a 'Missing' string. First, if you don't wish to permanently modify your original DataFrame, you can call `.fillna()` on the DataFrame being passed to the `pivot_table()` function. This ensures that rows with missing data get incorporated into the pivot table but leaves the original DataFrame untouched. \n",
    "\n",
    "The following code implements this approach via a *dict comprehension*. (For more on this valuable tool, see https://docs.python.org/3/tutorial/datastructures.html#dictionaries .) This approach allows me to use the same list of `index` values that I'll pass to `pivot_table()` to specify which columns' missing entries should get filled in. This results in cleaner and less error-prone code, as if I needed to update my index values twice, once for `pivot_table()` and once for `fillna()`, the two lists could easily get out of sync.\n",
    "\n",
    "(Another option, by the way, would be to fill missing entries within *all* columns with a 'Missing' string; this could be accomplished via `df_transactions_faulty.fillna('Missing')`. However, if some columns with missing data use float or integer types, this approach could either raise a warning or an error--as you'd be attempting to pass a string into a list of missing values. Thus, I recommend using the more precise solution shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e383b8a-6361-4d72-8c40-61629840ad3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T02:04:54.960438Z",
     "iopub.status.busy": "2025-02-25T02:04:54.960283Z",
     "iopub.status.idle": "2025-02-25T02:04:54.975326Z",
     "shell.execute_reply": "2025-02-25T02:04:54.975071Z",
     "shell.execute_reply.started": "2025-02-25T02:04:54.960429Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>weekday</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fr</td>\n",
       "      <td>Fr</td>\n",
       "      <td>13183.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fr</td>\n",
       "      <td>Missing</td>\n",
       "      <td>28856.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fr</td>\n",
       "      <td>Mo</td>\n",
       "      <td>20214.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fr</td>\n",
       "      <td>Sa</td>\n",
       "      <td>3739.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Se</td>\n",
       "      <td>Sa</td>\n",
       "      <td>1260.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Se</td>\n",
       "      <td>Su</td>\n",
       "      <td>2377.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Se</td>\n",
       "      <td>Th</td>\n",
       "      <td>7017.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Se</td>\n",
       "      <td>Tu</td>\n",
       "      <td>10613.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   level  weekday    amount\n",
       "0     Fr       Fr  13183.14\n",
       "1     Fr  Missing  28856.95\n",
       "2     Fr       Mo  20214.29\n",
       "3     Fr       Sa   3739.85\n",
       "..   ...      ...       ...\n",
       "24    Se       Sa   1260.53\n",
       "25    Se       Su   2377.25\n",
       "26    Se       Th   7017.18\n",
       "27    Se       Tu  10613.20\n",
       "\n",
       "[28 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = ['level', 'weekday'] # These values will get passed to the\n",
    "# index argument of our pivot_table() call.\n",
    "# The following dict comprehension will produce the dictionary\n",
    "# {'level': 'Missing', 'weekday': 'Missing'}--which, when passed to\n",
    "# fillna(), will instruct Pandas to fill in missing data with 'Missing' \n",
    "# only within those two fields.\n",
    "# (For more on this argument, see\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/\n",
    "# api/pandas.DataFrame.fillna.html )\n",
    "df_transactions_corrected_pivot = df_transactions_faulty.fillna(\n",
    "    {field:'Missing' for field in index}).pivot_table(\n",
    "    index = index, values = 'amount',\n",
    "    aggfunc = 'sum').reset_index()\n",
    "df_transactions_corrected_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10f5f9e-2668-4f30-a33f-cc929f20f8d2",
   "metadata": {},
   "source": [
    "Filling in missing 'level' and 'weekday' rows with 'Missing' allowed them to appear within our updated pivot table. As a result, we can now produce an accurate sum of all transactions by adding up the 'amount' rows within this table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20fb2820-687a-4d42-b7d3-b31e6d106bb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T02:04:54.975906Z",
     "iopub.status.busy": "2025-02-25T02:04:54.975653Z",
     "iopub.status.idle": "2025-02-25T02:04:54.978029Z",
     "shell.execute_reply": "2025-02-25T02:04:54.977756Z",
     "shell.execute_reply.started": "2025-02-25T02:04:54.975895Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(284156.99)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions_corrected_pivot['amount'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05744d75-1ab0-479a-a1b7-2ae714bb3501",
   "metadata": {},
   "source": [
    "The following approach permanently replaces missing weekday and level values with 'Missing', thus saving you the trouble of repeating this step later in your code. It also iterates through each field in the `index` list via a for loop in order to inform you which columns, in particular, have missing data. \n",
    "\n",
    "In some cases, it may be preferable for your code to halt upon finding missing data; this halt serves as an alert that missing data exists, thus prompting you to fill in those missing entries with their actual values. The commented-out code above the first print statement in the following cell would stop this script's operation (by raising a ValueError) if it came across any missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9d89bf0-627f-4001-a276-de5f8e0fa923",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T02:04:54.978554Z",
     "iopub.status.busy": "2025-02-25T02:04:54.978329Z",
     "iopub.status.idle": "2025-02-25T02:04:54.991264Z",
     "shell.execute_reply": "2025-02-25T02:04:54.991030Z",
     "shell.execute_reply.started": "2025-02-25T02:04:54.978544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level has NaN values; these will be filled with 'Missing' so that their rows' data can still get incorporated into the following pivot table.\n",
      "weekday has NaN values; these will be filled with 'Missing' so that their rows' data can still get incorporated into the following pivot table.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>weekday</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fr</td>\n",
       "      <td>Fr</td>\n",
       "      <td>13183.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fr</td>\n",
       "      <td>Missing</td>\n",
       "      <td>28856.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fr</td>\n",
       "      <td>Mo</td>\n",
       "      <td>20214.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fr</td>\n",
       "      <td>Sa</td>\n",
       "      <td>3739.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Se</td>\n",
       "      <td>Sa</td>\n",
       "      <td>1260.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Se</td>\n",
       "      <td>Su</td>\n",
       "      <td>2377.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Se</td>\n",
       "      <td>Th</td>\n",
       "      <td>7017.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Se</td>\n",
       "      <td>Tu</td>\n",
       "      <td>10613.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   level  weekday    amount\n",
       "0     Fr       Fr  13183.14\n",
       "1     Fr  Missing  28856.95\n",
       "2     Fr       Mo  20214.29\n",
       "3     Fr       Sa   3739.85\n",
       "..   ...      ...       ...\n",
       "24    Se       Sa   1260.53\n",
       "25    Se       Su   2377.25\n",
       "26    Se       Th   7017.18\n",
       "27    Se       Tu  10613.20\n",
       "\n",
       "[28 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for val in index:\n",
    "    if df_transactions_faulty[val].isna().sum() > 0:\n",
    "#         raise ValueError(f\"{val} has NaN values; address these before \\\n",
    "# running the following pivot table operation.\")\n",
    "        print(f\"{val} has NaN values; these will be filled with 'Missing' \\\n",
    "so that their rows' data can still get incorporated into the following \\\n",
    "pivot table.\")\n",
    "        df_transactions_faulty[val] = df_transactions_faulty[val].fillna(\n",
    "            'Missing').copy()\n",
    "        \n",
    "df_transactions_corrected_pivot = df_transactions_faulty.pivot_table(\n",
    "    index = index, values = 'amount',\n",
    "    aggfunc = 'sum').reset_index()\n",
    "df_transactions_corrected_pivot\n",
    "                         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a1dba5-3c6e-4fb1-9139-4bc4bf9f384b",
   "metadata": {},
   "source": [
    "This new version of `df_transactions_corrected_pivot` also lets us calculate an accurate sum of all transactions within the original dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d8ee828-2aa8-44ed-9937-4a6d378c8493",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T02:04:54.991729Z",
     "iopub.status.busy": "2025-02-25T02:04:54.991585Z",
     "iopub.status.idle": "2025-02-25T02:04:54.994099Z",
     "shell.execute_reply": "2025-02-25T02:04:54.993804Z",
     "shell.execute_reply.started": "2025-02-25T02:04:54.991718Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(217029.91999999998)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions_faulty_pivot['amount'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568ec08f-0772-41f3-89e1-8f4a94f9d70d",
   "metadata": {},
   "source": [
    "By the way, the following code would also have allowed us to permanently fill in all missing values within the columns in our `index` list. This code is similar to that used in the first approach, except that it saves its updates back to df_transactions_faulty, thus making them persistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc8dd998-0f8d-4c5a-9529-dab72d5d6cd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T02:04:54.994504Z",
     "iopub.status.busy": "2025-02-25T02:04:54.994399Z",
     "iopub.status.idle": "2025-02-25T02:04:55.000058Z",
     "shell.execute_reply": "2025-02-25T02:04:54.999708Z",
     "shell.execute_reply.started": "2025-02-25T02:04:54.994494Z"
    }
   },
   "outputs": [],
   "source": [
    "df_transactions_faulty = df_transactions_faulty.fillna(\n",
    "    {field:'Missing' for field in index}).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979885a5-7fd2-4438-b38f-27ddec965a44",
   "metadata": {},
   "source": [
    "I'll now undo my corrections to df_transactions_faulty in order to prepare the dataset for the following section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1becdbba-2043-419e-99bf-02217906e1fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T02:04:55.000520Z",
     "iopub.status.busy": "2025-02-25T02:04:55.000394Z",
     "iopub.status.idle": "2025-02-25T02:04:55.006950Z",
     "shell.execute_reply": "2025-02-25T02:04:55.006721Z",
     "shell.execute_reply.started": "2025-02-25T02:04:55.000510Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starting_year</th>\n",
       "      <th>weekday</th>\n",
       "      <th>level</th>\n",
       "      <th>amount</th>\n",
       "      <th>transactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fr</td>\n",
       "      <td>13.36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>Tu</td>\n",
       "      <td>Se</td>\n",
       "      <td>12.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Se</td>\n",
       "      <td>23.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>Su</td>\n",
       "      <td>Fr</td>\n",
       "      <td>18.78</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22449</th>\n",
       "      <td>2023</td>\n",
       "      <td>Tu</td>\n",
       "      <td>Fr</td>\n",
       "      <td>5.98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22450</th>\n",
       "      <td>2023</td>\n",
       "      <td>Fr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22451</th>\n",
       "      <td>2023</td>\n",
       "      <td>Sa</td>\n",
       "      <td>Fr</td>\n",
       "      <td>13.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22452</th>\n",
       "      <td>2023</td>\n",
       "      <td>Mo</td>\n",
       "      <td>Fr</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22453 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       starting_year weekday level  amount  transactions\n",
       "0               2023     NaN    Fr   13.36             1\n",
       "1               2023      Tu    Se   12.22             1\n",
       "2               2023     NaN    Se   23.10             1\n",
       "3               2023      Su    Fr   18.78             1\n",
       "...              ...     ...   ...     ...           ...\n",
       "22449           2023      Tu    Fr    5.98             1\n",
       "22450           2023      Fr   NaN    7.39             1\n",
       "22451           2023      Sa    Fr   13.25             1\n",
       "22452           2023      Mo    Fr    1.95             1\n",
       "\n",
       "[22453 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Undoing my corrections to df_transactions_faulty:\n",
    "df_transactions_faulty.replace(\n",
    "    'Missing', np.nan, inplace = True)\n",
    "df_transactions_faulty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80080f6e-a49b-4c31-9430-195b65806c48",
   "metadata": {},
   "source": [
    "## The advantages of map() and np.select() over np.where() when missing data are present\n",
    "\n",
    "Suppose we'd like to find the total number of dining hall transactions that took place on the weekend versus those that didn't. To make this calculation easier, we can add a 'weekday' column that will store a value of 1 if a transaction fell on Saturday or Sunday and 0 otherwise. \n",
    "\n",
    "We could try initializing this column via np.where(). The following cell uses this function to assign a 'weekend' value of 0 to all transactions whose 'weekday' value corresponds to Monday, Tuesday, Wednesday, Thursday, or Friday. Transactions that don't have one of these weekday values are classified as weekend sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a0ce594-ab64-49ff-be26-f3a315b4cacd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T02:04:55.007390Z",
     "iopub.status.busy": "2025-02-25T02:04:55.007242Z",
     "iopub.status.idle": "2025-02-25T02:04:55.014462Z",
     "shell.execute_reply": "2025-02-25T02:04:55.014215Z",
     "shell.execute_reply.started": "2025-02-25T02:04:55.007380Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starting_year</th>\n",
       "      <th>weekday</th>\n",
       "      <th>...</th>\n",
       "      <th>transactions</th>\n",
       "      <th>weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>Tu</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>Su</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22449</th>\n",
       "      <td>2023</td>\n",
       "      <td>Tu</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22450</th>\n",
       "      <td>2023</td>\n",
       "      <td>Fr</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22451</th>\n",
       "      <td>2023</td>\n",
       "      <td>Sa</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22452</th>\n",
       "      <td>2023</td>\n",
       "      <td>Mo</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22453 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       starting_year weekday  ... transactions  weekend\n",
       "0               2023     NaN  ...            1        1\n",
       "1               2023      Tu  ...            1        0\n",
       "2               2023     NaN  ...            1        1\n",
       "3               2023      Su  ...            1        1\n",
       "...              ...     ...  ...          ...      ...\n",
       "22449           2023      Tu  ...            1        0\n",
       "22450           2023      Fr  ...            1        0\n",
       "22451           2023      Sa  ...            1        1\n",
       "22452           2023      Mo  ...            1        0\n",
       "\n",
       "[22453 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions_faulty['weekend'] = np.where(\n",
    "    df_transactions_faulty['weekday'].isin(\n",
    "        ['Mo', 'Tu', 'We', 'Th', 'Fr']), 0, 1)\n",
    "df_transactions_faulty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72765745-8cf5-4b6a-b956-d7320ec158cc",
   "metadata": {},
   "source": [
    "The issue with this approach, as you might have recognized already, is that it classifies all transactions with missing 'weekday' values as taking place during the weekend. We know that this is inaccurate: the transactions with missing weekday entries actually took place on Wednesday. (In real life, of course, we wouldn't know this to be the case--but we still wouldn't want to assume that they fell on the weekend.)\n",
    "\n",
    "Here is the total number of Saturday and Sunday dining hall transactions according to our 'weekend' column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f08a8d4-de5e-4609-ad5d-691370585e1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T02:04:55.014994Z",
     "iopub.status.busy": "2025-02-25T02:04:55.014782Z",
     "iopub.status.idle": "2025-02-25T02:04:55.018697Z",
     "shell.execute_reply": "2025-02-25T02:04:55.018464Z",
     "shell.execute_reply.started": "2025-02-25T02:04:55.014984Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7148"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_transactions_faulty.query(\"weekend == 1\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d6c242-3970-49a6-9575-ded3e2e37fa9",
   "metadata": {},
   "source": [
    "As it turns out, this sum much higher than the correct value (which we can calculate using our original transactions table):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d608abf2-c25e-4add-ae3b-bed6c0f7ab15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T02:04:55.019236Z",
     "iopub.status.busy": "2025-02-25T02:04:55.019041Z",
     "iopub.status.idle": "2025-02-25T02:04:55.023010Z",
     "shell.execute_reply": "2025-02-25T02:04:55.022795Z",
     "shell.execute_reply.started": "2025-02-25T02:04:55.019227Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1831"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_transactions.query(\"weekday in ['Sa', 'Su']\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e45de8-634a-4b33-b234-52cbd91f7709",
   "metadata": {},
   "source": [
    "Let's now overwrite this faulty 'weekend' column by using `map()` instead. This function will allow us to map each individual weekday value to either 1 (for weekend) entries or 0 (for non-weekend values). Importantly, it also lets us map np.nan (i.e. missing) entries to a third number, -1: this number represents neither weekend nor non-weekend entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b505a40-2420-470f-9127-27211ecd41f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T02:04:55.023418Z",
     "iopub.status.busy": "2025-02-25T02:04:55.023288Z",
     "iopub.status.idle": "2025-02-25T02:04:55.030363Z",
     "shell.execute_reply": "2025-02-25T02:04:55.030119Z",
     "shell.execute_reply.started": "2025-02-25T02:04:55.023408Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starting_year</th>\n",
       "      <th>weekday</th>\n",
       "      <th>...</th>\n",
       "      <th>transactions</th>\n",
       "      <th>weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>Tu</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>Su</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22449</th>\n",
       "      <td>2023</td>\n",
       "      <td>Tu</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22450</th>\n",
       "      <td>2023</td>\n",
       "      <td>Fr</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22451</th>\n",
       "      <td>2023</td>\n",
       "      <td>Sa</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22452</th>\n",
       "      <td>2023</td>\n",
       "      <td>Mo</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22453 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       starting_year weekday  ... transactions  weekend\n",
       "0               2023     NaN  ...            1       -1\n",
       "1               2023      Tu  ...            1        0\n",
       "2               2023     NaN  ...            1       -1\n",
       "3               2023      Su  ...            1        1\n",
       "...              ...     ...  ...          ...      ...\n",
       "22449           2023      Tu  ...            1        0\n",
       "22450           2023      Fr  ...            1        0\n",
       "22451           2023      Sa  ...            1        1\n",
       "22452           2023      Mo  ...            1        0\n",
       "\n",
       "[22453 rows x 6 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions_faulty['weekend'] = (\n",
    "    df_transactions_faulty['weekday'].map(\n",
    "    {'Su':0, 'Mo':0, 'Tu': 0, 'We':0, 'Th':0, 'Fr':0, 'Sa':1, 'Su':1,\n",
    "     np.nan:-1}))\n",
    "df_transactions_faulty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d28e0c-f813-4af0-9847-2a99000bacb7",
   "metadata": {},
   "source": [
    "If we apply value_counts() to this column, we'll find that our weekend transactions count matches that shown above. The sum for the -1 entry shows the number of transactions that are missing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "74e49791-5f89-4470-86db-7188f3218c8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T02:04:55.030913Z",
     "iopub.status.busy": "2025-02-25T02:04:55.030717Z",
     "iopub.status.idle": "2025-02-25T02:04:55.033537Z",
     "shell.execute_reply": "2025-02-25T02:04:55.033303Z",
     "shell.execute_reply.started": "2025-02-25T02:04:55.030902Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weekend\n",
       " 0    15305\n",
       "-1     5317\n",
       " 1     1831\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions_faulty['weekend'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a3c86b-1188-4c90-9e64-cc9c285ff224",
   "metadata": {},
   "source": [
    "I could have also chosen to use 'Missing' as my marker for invalid data; however, since the other values output by `map()` were integers, I wanted to make the missing data code an integer also.\n",
    "\n",
    "As an aside, the use of 1 for weekend transactions and 0 for work-week ones makes it easy to determine the percentage of transactions that took place over the weekend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a5d46d4-7cc4-498d-a67b-dcedb55f1e5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T02:04:55.034056Z",
     "iopub.status.busy": "2025-02-25T02:04:55.033836Z",
     "iopub.status.idle": "2025-02-25T02:04:55.037669Z",
     "shell.execute_reply": "2025-02-25T02:04:55.037426Z",
     "shell.execute_reply.started": "2025-02-25T02:04:55.034047Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.69% of transactions with valid weekday entries took place on a Saturday or Sunday.\n"
     ]
    }
   ],
   "source": [
    "print(f\"{\n",
    "round(100*df_transactions_faulty.query(\n",
    "    \"weekend != -1\")['weekend'].mean(), 2)}% of transactions with valid \\\n",
    "weekday entries took place on a Saturday or Sunday.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9de6ed6-bed3-42da-802c-1da34f51af2e",
   "metadata": {},
   "source": [
    "Note the 'with valid weekday entries' caveat in the above print statement. Since we wouldn't know for sure on which weekdays the missing transactions took place, we wouldn't want our statement to make any assertionss about them.\n",
    "\n",
    "It was also crucial to exclude rows with weekend values of -1 from our above calculation. If we had kept them in, we would have ended up with a nonsensical percentage of weekend transactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e57bc73e-8160-4975-ad52-f4aca0369c61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T02:04:55.038176Z",
     "iopub.status.busy": "2025-02-25T02:04:55.038020Z",
     "iopub.status.idle": "2025-02-25T02:04:55.039956Z",
     "shell.execute_reply": "2025-02-25T02:04:55.039724Z",
     "shell.execute_reply.started": "2025-02-25T02:04:55.038166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-15.53% of transactions took place on a Saturday or Sunday . . . wait, really? I think I need to double-check these numbers . . . \n"
     ]
    }
   ],
   "source": [
    "print(f\"{round(100 * df_transactions_faulty['weekend'].mean(), 2)}% \\\n",
    "of transactions took place on a Saturday or Sunday . . . wait, really? \\\n",
    "I think I need to double-check these numbers . . . \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505024f2-56df-4d9d-a7ea-f19920bc2bb8",
   "metadata": {},
   "source": [
    "If you're categorizing continuous rather than categorical data, the `map()` approach above will be hard to implement--as you might end up having to code a ton of values. Therefore, you should use `np.select()` instead. This function generally involves a bit more code than `map()` for categorical data, but it easily accommodates continuous values as well.\n",
    "\n",
    "Let's say that we want to add a 'large_purchase' flag to each row that will be 1 if the amount was at or above the 90th percentile and 0 otherwise. We could then use this flag to determine each level's likelihood of making such a large purchase.\n",
    "\n",
    "The 90th percentile can be calculated as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3d434da6-b99a-43e1-ab0c-f60a46baa808",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T02:04:55.040378Z",
     "iopub.status.busy": "2025-02-25T02:04:55.040237Z",
     "iopub.status.idle": "2025-02-25T02:04:55.043845Z",
     "shell.execute_reply": "2025-02-25T02:04:55.043605Z",
     "shell.execute_reply.started": "2025-02-25T02:04:55.040369Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(24.067999999999994)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_purchase_threshold = df_transactions['amount'].quantile(0.9)\n",
    "# See https://pandas.pydata.org/docs/reference/api/\n",
    "# pandas.DataFrame.quantile.html\n",
    "large_purchase_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda6617a-d734-46f8-b0e0-b322b3247bf9",
   "metadata": {},
   "source": [
    "The following code will simplify df_transactions_faulty by removing some columns that won't be needed for the following section. It will also introduce missing numerical data by replacing all transactions whose final digit is a 6 with np.nan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db16ddb3-3cbe-41ee-9aaa-c06c5531cf5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T02:04:55.044293Z",
     "iopub.status.busy": "2025-02-25T02:04:55.044199Z",
     "iopub.status.idle": "2025-02-25T02:04:55.062544Z",
     "shell.execute_reply": "2025-02-25T02:04:55.062308Z",
     "shell.execute_reply.started": "2025-02-25T02:04:55.044284Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starting_year</th>\n",
       "      <th>level</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>Fr</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>Se</td>\n",
       "      <td>12.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>Se</td>\n",
       "      <td>23.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>Fr</td>\n",
       "      <td>18.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22449</th>\n",
       "      <td>2023</td>\n",
       "      <td>Fr</td>\n",
       "      <td>5.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22450</th>\n",
       "      <td>2023</td>\n",
       "      <td>So</td>\n",
       "      <td>7.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22451</th>\n",
       "      <td>2023</td>\n",
       "      <td>Fr</td>\n",
       "      <td>13.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22452</th>\n",
       "      <td>2023</td>\n",
       "      <td>Fr</td>\n",
       "      <td>1.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22453 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       starting_year level  amount\n",
       "0               2023    Fr     NaN\n",
       "1               2023    Se   12.22\n",
       "2               2023    Se   23.10\n",
       "3               2023    Fr   18.78\n",
       "...              ...   ...     ...\n",
       "22449           2023    Fr    5.98\n",
       "22450           2023    So    7.39\n",
       "22451           2023    Fr   13.25\n",
       "22452           2023    Fr    1.95\n",
       "\n",
       "[22453 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions_faulty = df_transactions.copy().drop(\n",
    "    ['weekday', 'transactions'], \n",
    "    axis = 1)\n",
    "\n",
    "df_transactions_faulty['amount'] = np.where(\n",
    "    df_transactions_faulty['amount'].astype('str').str[-1] == '6', \n",
    "    np.nan, df_transactions_faulty['amount'])\n",
    "\n",
    "df_transactions_faulty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12121662-0a1d-43e0-b63e-674044d83fdf",
   "metadata": {},
   "source": [
    "We wouldn't want to use `np.where()` to initialize our 'large_purchase' column, as we would inadvertently group missing transactions as large or non-large. In addition, `map()` would be a poor solution, as we now have thousands of unique values to code rather than just a few:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "97f57144-5d24-48b5-ae9f-5db2c2ccf461",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T02:04:55.062983Z",
     "iopub.status.busy": "2025-02-25T02:04:55.062875Z",
     "iopub.status.idle": "2025-02-25T02:04:55.065457Z",
     "shell.execute_reply": "2025-02-25T02:04:55.065210Z",
     "shell.execute_reply.started": "2025-02-25T02:04:55.062973Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3131"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_transactions_faulty['amount'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d53b208-bcaa-4578-8e8f-aa6923d93243",
   "metadata": {},
   "source": [
    "Therefore, we'll instead use `np.select()`. This function applies a `condlist` (a list of possible conditions) and a `choicelist` (a list of values to apply for each of those conditions) in order to initialize or update a given column. (You don't have to name these items `condlist` and `choicelist`, but those are their corresponding parameter names; see https://numpy.org/doc/stable/reference/generated/numpy.select.html ). Importantly, this function also has a `default` argument that lets you determine what value to enter if none of the conditions were met. \n",
    "\n",
    "The following code applies `np.select()` by defining two possible conditions (e.g. a transaction is above the threshold or it isn't) and two corresponding values to enter within our 'large_purchase' column (1 or 0). It also adds a 'default' value of -1; this value will get added to the large_purchase column when a given transaction amount is missing. (Note that, if no default value is specified, numpy will add values of 0--which would easily get mistaken for the 'not a large purchase' condition.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "561c7366-21d6-499b-8631-b0f8cbf60577",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T02:04:55.065992Z",
     "iopub.status.busy": "2025-02-25T02:04:55.065756Z",
     "iopub.status.idle": "2025-02-25T02:04:55.070930Z",
     "shell.execute_reply": "2025-02-25T02:04:55.070711Z",
     "shell.execute_reply.started": "2025-02-25T02:04:55.065981Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starting_year</th>\n",
       "      <th>level</th>\n",
       "      <th>amount</th>\n",
       "      <th>large_purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>Fr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>Se</td>\n",
       "      <td>12.22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>Se</td>\n",
       "      <td>23.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>Fr</td>\n",
       "      <td>18.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22449</th>\n",
       "      <td>2023</td>\n",
       "      <td>Fr</td>\n",
       "      <td>5.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22450</th>\n",
       "      <td>2023</td>\n",
       "      <td>So</td>\n",
       "      <td>7.39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22451</th>\n",
       "      <td>2023</td>\n",
       "      <td>Fr</td>\n",
       "      <td>13.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22452</th>\n",
       "      <td>2023</td>\n",
       "      <td>Fr</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22453 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       starting_year level  amount  large_purchase\n",
       "0               2023    Fr     NaN              -1\n",
       "1               2023    Se   12.22               0\n",
       "2               2023    Se   23.10               0\n",
       "3               2023    Fr   18.78               0\n",
       "...              ...   ...     ...             ...\n",
       "22449           2023    Fr    5.98               0\n",
       "22450           2023    So    7.39               0\n",
       "22451           2023    Fr   13.25               0\n",
       "22452           2023    Fr    1.95               0\n",
       "\n",
       "[22453 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condlist = [\n",
    "    df_transactions_faulty['amount'] >= large_purchase_threshold,\n",
    "    df_transactions_faulty['amount'] <= large_purchase_threshold\n",
    "]\n",
    "\n",
    "choicelist = [1,\n",
    "              0] # Make sure that the order of these entries matches\n",
    "# the order of your condlist entries!\n",
    "\n",
    "df_transactions_faulty['large_purchase'] = np.select(\n",
    "    condlist, choicelist, default = -1)\n",
    "df_transactions_faulty   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dc6483-faeb-4bb5-9169-4daa43646fac",
   "metadata": {},
   "source": [
    "Now that we've added in this column, we can create a pivot table that shows the likelihood, for each level, that a given transaction was at or above the 90th percentile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "55e361fb-13e0-42c6-a583-4caef650b47d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-25T02:04:55.071374Z",
     "iopub.status.busy": "2025-02-25T02:04:55.071218Z",
     "iopub.status.idle": "2025-02-25T02:04:55.078481Z",
     "shell.execute_reply": "2025-02-25T02:04:55.078228Z",
     "shell.execute_reply.started": "2025-02-25T02:04:55.071364Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>large_purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fr</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ju</td>\n",
       "      <td>0.297705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Se</td>\n",
       "      <td>0.434444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So</td>\n",
       "      <td>0.081307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  level  large_purchase\n",
       "0    Fr        0.000000\n",
       "1    Ju        0.297705\n",
       "2    Se        0.434444\n",
       "3    So        0.081307"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions_faulty.query(\"large_purchase != -1\").pivot_table(\n",
    "    index = 'level', \n",
    "    values = 'large_purchase', aggfunc = 'mean').reset_index()\n",
    "                                   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010d8606-d0d4-4103-96c7-9ddcacda72dc",
   "metadata": {},
   "source": [
    "This likelihood is evidently much higher for upperclassmen (juniors and seniors) than for underclassmen (freshmen and sophomores). Of course, this analysis isn't perfect, as it's limited to the rows for which we have valid transaction amounts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
