{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0992234a-6e17-4547-9687-c0d7c196350b",
   "metadata": {},
   "source": [
    "# census_import_scripts.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "204ee838-2ae3-47d9-8c39-cfc77fe19c44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-21T03:21:21.970250Z",
     "iopub.status.busy": "2025-02-21T03:21:21.969978Z",
     "iopub.status.idle": "2025-02-21T03:21:21.980628Z",
     "shell.execute_reply": "2025-02-21T03:21:21.980226Z",
     "shell.execute_reply.started": "2025-02-21T03:21:21.970234Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python file creates scripts for creating lists of American\n",
    "# Community Survey variables; generating aliases for variable codes;\n",
    "# using the Census API to download data; and adding certain statistical\n",
    "# fields to tables.\n",
    "\n",
    "import pandas as pd\n",
    "from iteration_utilities import duplicates\n",
    "\n",
    "def download_variable_list(year, survey):\n",
    "    '''This function imports a list of all variables from the Census\n",
    "    website, thus allowing variable codes to get mapped to names in \n",
    "    subsequent analyses.\n",
    "    year: the year for which to retrieve variables.\n",
    "    survey: the ACS type for which to retrieve variables (e.g.\n",
    "    'acs5' or 'acs1' for the 5-year and 1-year ACS estimates,\n",
    "    respectively.)\n",
    "    '''\n",
    "    print(f\"Importing {survey} variables from {year}.\")\n",
    "    df_variables_page = pd.read_html(\n",
    "        f'https://api.census.gov/data/\\\n",
    "{year}/acs/{survey}/variables.html')[0] \n",
    "    # [0] selects the first HTML table found on this page.\n",
    "    # See https://pandas.pydata.org/pandas-docs/stable/reference/api/\n",
    "    # pandas.read_html.html\n",
    "    # for more information on pd.read_html().\n",
    "        \n",
    "    # Some rows in this table contain items other than demographic \n",
    "    # variables (e.g. region names). We can exclude them by selecting \n",
    "    # only rows that begin with 'Estimate'. (Another option would have \n",
    "    # been to filter out rows with N/A 'Group' entries (i.e. \n",
    "    # df_variables.query(\"Group.isna() == False\")), \n",
    "    # but this would have left a couple non-variable rows in place.\n",
    "    \n",
    "    df_variables = df_variables_page[\n",
    "    df_variables_page['Label'].str[0:8] == 'Estimate'].copy(\n",
    "    ).reset_index(drop=True)\n",
    "    # Removing an extraneous column from our output\n",
    "    if 'Unnamed: 8' in df_variables.columns:\n",
    "        df_variables.drop('Unnamed: 8', axis = 1, inplace = True)\n",
    "    # Saving this table to a local .csv file:\n",
    "    df_variables.to_csv(f'Datasets/{survey}_{year}_variables.csv',\n",
    "                       index = False) \n",
    "\n",
    "    # Given that there are tens of thousands of individual variables\n",
    "    # within the ACS, it could take a very long time to identify \n",
    "    # the items you'd like to retrieve from this dataset. \n",
    "    # The following code makes this search process somewhat easier by \n",
    "    # creating a separate *groups* table that shows only unique group \n",
    "    # names and their written descriptions (e.g. 'Sex by Age').\n",
    "    \n",
    "    df_groups = df_variables.drop_duplicates(\n",
    "        'Group')[['Concept', 'Group']].copy(\n",
    "        ).reset_index(drop=True)\n",
    "    df_groups.head()\n",
    "\n",
    "    df_groups.to_csv(f'Datasets/{survey}_{year}_groups.csv', \n",
    "                 index = False)\n",
    "\n",
    "    \n",
    "    print(f\"Finished saving variable and group tables to .csv files.\")\n",
    "    \n",
    "\n",
    "def create_variable_aliases(df_variables, variable_list):\n",
    "    '''This function creates a dictionary whose keys are \n",
    "    the original 'Name' values (e.g. 'B001_001E') within a variable\n",
    "    list on the Census API website and whose values are the replacement \n",
    "    names (e.g. 'Sex by Age_Estimate!!Total:_B01001_001E').\n",
    "    This resulting dictionary can then be passed to a df.rename() call\n",
    "    within retrieve_census_data() in order to make the output of that\n",
    "    function easier to interpret.\n",
    "    \n",
    "    df_variables: A DataFrame containing a list of Census variables. For\n",
    "    an example of this list for the 2021 American Community Survey (5-Year \n",
    "    Estimates), visit: \n",
    "    https://api.census.gov/data/2021/acs/acs5/examples.html .\n",
    "    \n",
    "    variable_list: The list of variables to rename \n",
    "    (e.g. ['B01001_001E', 'B01001_002E']).\n",
    "    '''\n",
    "    # Creating a DataFrame that contains the information needed for the\n",
    "    # updated column names:\n",
    "    df_aliases = df_variables.query(\n",
    "        \"Name in @variable_list\")[['Name', 'Label', 'Concept']].copy()\n",
    "    # Creating a new 'Description' column that will replace the original\n",
    "    # output field names:\n",
    "    df_aliases['Description'] = (df_aliases['Concept'] \n",
    "                                 + '_' + df_aliases['Label'] \n",
    "                                 + ' (' + df_aliases['Name'] + ')')\n",
    "    # Creating a dictionary whose keys are the original field names and \n",
    "    # whose values are the new 'Description' entries that were \n",
    "    # just created:\n",
    "    alias_dict = df_aliases.set_index('Name').to_dict()['Description']\n",
    "    # See https://pandas.pydata.org/pandas-docs/stable/reference/api/\n",
    "    # pandas.DataFrame.to_dict.html\n",
    "    return alias_dict\n",
    "\n",
    "\n",
    "def retrieve_census_data(survey, year, region, key, variable_list,\n",
    "                         rename_data_fields = False, \n",
    "                         field_vars_dict = {}):\n",
    "    '''This function (which I plan to expand) retrieves data from the US\n",
    "    Census API. It accommodates more than 50 variables.\n",
    "    \n",
    "    survey: the survey from which to retrieve data. The only arguments\n",
    "    currently supported are 'acs5' and 'acs1' (for the American Community \n",
    "    Survey 5-Year and 1-Year estimates, respectively).\n",
    "    \n",
    "    year: the year for which you wish to retrieve survey data. Note that,\n",
    "    When region is set to 'acs5', the survey results will include data\n",
    "    for the 5 years leading up to (and including) the 'year' argument.\n",
    "    (For example, if you set 'year' to 2021, you'll retrieve ACS5 data\n",
    "    from 2017 to 2021 (inclusive).)\n",
    "    \n",
    "    \n",
    "    region: The geographic level at which you wish to retrieve data. \n",
    "    Examples include 'us', 'state', 'county', 'zip', 'msa' \n",
    "    (for metropolitan/micropolitan statistical area data), and 'csa' \n",
    "    (for combined statistical area data); \n",
    "    however, other regions are supported as well. Consult your survey's \n",
    "    API examples page for other options. (For instance, if you wanted to \n",
    "    retrieve data by urban area within the 2021 ACS5, you could go to \n",
    "    https://api.census.gov/data/2021/acs/acs5/examples.html, then search\n",
    "    for 'urban area.' The Urban Area URL ends with\n",
    "    '&for=urban%20area:*&key=YOUR_KEY_GOES_HERE'. Therefore, you'd want to\n",
    "    use 'urban%20area' as your 'region' argument.)   \n",
    "\n",
    "    (Note: 'zip' will retrieve results by Zip Code\n",
    "    Tabulation Area, which are similar to (but not identical to)\n",
    "    # zip codes. See \n",
    "    # https://en.wikipedia.org/wiki/ZIP_Code_Tabulation_Area\n",
    "    # for more information.\n",
    "    \n",
    "    variable_list: The list of variables for which to retrieve data.\n",
    "\n",
    "    key: your personal Census API key.\n",
    "\n",
    "    rename_data_fields: set to True to replace column names in your \n",
    "    dataset with new entries of your choice.\n",
    "\n",
    "    field_vars_dict: A dictionary that stores the original variable names\n",
    "    retrieved by the Census (e.g. 'B01001_001E' as keys and your desired\n",
    "    replacements as values. Example: \n",
    "    {'B01001_001E': 'Sex by Age_Estimate!!Total:_B01001_001E',\n",
    "     'B01001_002E': 'Sex by Age_Estimate!!Total:!!Male:_B01001_002E'}'\n",
    "     \n",
    "    '''\n",
    "\n",
    "    # Using the iteration_utilities library to check for duplicate\n",
    "    # values within variable_list (which could cause issues later on):\n",
    "    # The following code is based on\n",
    "    # https://iteration-utilities.readthedocs.io/en/latest/generated/\n",
    "    # duplicates.html\n",
    "    duplicate_variables = list(duplicates(variable_list))\n",
    "    \n",
    "    if len(duplicate_variables) > 0:\n",
    "        raise ValueError(f\"The following variables appear more than once \\\n",
    "in your variable list: {duplicate_variables}\")\n",
    "    \n",
    "    if survey == 'acs5':\n",
    "        survey_string = 'acs/acs5'\n",
    "\n",
    "    elif survey == 'acs1':\n",
    "        survey_string = 'acs/acs1'\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"This survey type is not currently supported by \\\n",
    "                         the function.\")\n",
    "\n",
    "    \n",
    "    # Converting simplified region names into strings that the API \n",
    "    # function will recognize:\n",
    "    if region == 'zip':\n",
    "        region = 'zip%20code%20tabulation%20area' # Based on\n",
    "        # the ZCTA example within\n",
    "        # https://api.census.gov/data/2021/acs/acs5/examples.html\n",
    "    \n",
    "    if region == 'csa':\n",
    "        region = 'combined%20statistical%20area'\n",
    "    \n",
    "    if region == 'msa':\n",
    "        region = 'metropolitan%20statistical\\\n",
    "%20area/micropolitan%20statistical%20area'\n",
    "\n",
    "    \n",
    "    # Only 50 variables can be retrieved from the Census API at a time \n",
    "    # using the approach shown in this function. The following code \n",
    "    # accommodates this limitation by splitting variable_list into \n",
    "    # sublists of up to 49 variables. The data retrieved for the variables \n",
    "    # in these sublists will then get merged back together.\n",
    "    # (49 variables are retrieved at a time instead of 50 because it \n",
    "    # appears that the initial 'NAME' variable also counts towards \n",
    "    # the 50-variable limit.)\n",
    "    \n",
    "    i = 0\n",
    "       \n",
    "    while i < len(variable_list): # i.e. while there\n",
    "        # are still more variables to iterate through\n",
    "        variable_sublist = variable_list[i:i+49] # This line reads the \n",
    "        # next 49 variables from variable_list into a sublist that can \n",
    "        # then be\\ passed to the API\n",
    "        # print(\"variable_sublist:\", variable_sublist)\n",
    "        # Converting the list of variables into a string that can be \n",
    "        # passed to the API call:\n",
    "        # (The Census API guide at\n",
    "        # https://www.census.gov/content/dam/Census/data/developers/\n",
    "        # api-user-guide/api-guide.pdf\n",
    "        # demonstrates how to call multiple census variables at once.)\n",
    "        variable_string = ','.join(variable_sublist)\n",
    "        # print(\"variable_string:\",variable_string)\n",
    "    \n",
    "        # Retrieving data via the Census API:\n",
    "        # This line was originally based on an example found in\n",
    "        # https://api.census.gov/data/2022/acs/acs5/examples.html .\n",
    "    \n",
    "        # read_json documentation:\n",
    "        # https://pandas.pydata.org/pandas-docs/stable/reference/api/\n",
    "        # pandas.read_json.html\n",
    "\n",
    "        api_url = f'https://api.census.gov/data/{year}/\\\n",
    "{survey_string}?get=NAME,{variable_string}&for={region}:*&key={key}'\n",
    "        # print(api_url)\n",
    "        \n",
    "        df_results = pd.read_json(api_url)\n",
    "    \n",
    "        # At this point, the DataFrame's columns are a list of integers; \n",
    "        # the desired column names are stored within the first row. \n",
    "        # The following code resolves this issue by setting these row \n",
    "        # values as the column values and then deleting this row.\n",
    "    \n",
    "        df_results.columns = df_results.iloc[0]\n",
    "        df_results.drop(0, inplace = True)\n",
    "\n",
    "\n",
    "        # Determining which merge keys to use when combining API results\n",
    "        # for different sublists together:\n",
    "        # This is made more complicated by the fact that results for \n",
    "        # different regions will have different identifier\n",
    "        # columns (e.g. 'NAME', 'county', and 'state' for county data but \n",
    "        # only 'NAME' and 'state' for state data). However, we can \n",
    "        # accommodate this behavior by simply initializing our list of \n",
    "        # merge keys as the set of all columns that are *not* also \n",
    "        # variable columns.\n",
    "        if i == 0: # This step only needs to be performed for our first\n",
    "            # sublist of variables, since merge keys for other sublists\n",
    "            # will be identical.\n",
    "            merge_keys = list(set(df_results.columns) \n",
    "              - set(variable_sublist))\n",
    "            # print(\"merge_keys:\",merge_keys)\n",
    "\n",
    "        if i == 0: # Since this is the first set \n",
    "            # of results, we can initialize df_combined_results \n",
    "            # as a copy of df_results.\n",
    "            df_combined_results = df_results.copy()\n",
    "        else: # Merging our latest set of results into df_results:\n",
    "            df_combined_results = df_combined_results.merge(\n",
    "                df_results, on = merge_keys,\n",
    "                how = 'outer').copy()\n",
    "            # Added .copy() here in response to a data fragmentation \n",
    "        # warning\n",
    "\n",
    "        i += 49 \n",
    "        # Allows the function to iterate through the next 49 variables\n",
    "        # within variable_list\n",
    "\n",
    "        \n",
    "    # Converting variable columns to numeric data types:\n",
    "    for column in variable_list:\n",
    "        # print(f\"Now converting {column} to a numeric type.\")\n",
    "        df_combined_results[column] = pd.to_numeric(\n",
    "            df_combined_results[column])\n",
    "        # pd.to_numeric() allows for either integer or float outputs\n",
    "        # depending on the nature of the original data.\n",
    "        # See https://pandas.pydata.org/pandas-docs/stable/reference/api/\n",
    "        # pandas.to_numeric.html\n",
    "\n",
    "    # Replacing column names with aliases if requested:\n",
    "    if rename_data_fields == True:\n",
    "        df_combined_results.rename(\n",
    "            columns = field_vars_dict, inplace = True)\n",
    "\n",
    "    # The following for loop moves all of the merge keys (e.g. geographic\n",
    "    # identifiers) to the left side of the table. This is particularly\n",
    "    # useful when retrieving longer lists of variables, as otherwise,\n",
    "    # certain keys can get buried in the middle of the dataset\n",
    "    for i in range(len(merge_keys)):\n",
    "        df_combined_results.insert(\n",
    "            i, merge_keys[i], \n",
    "            df_combined_results.pop(merge_keys[i]))\n",
    "\n",
    "    # Adding a 'Year' column to the left of all existing DataFrame columns:\n",
    "    # (this will prove particularly\n",
    "    # helpful when comparing data from different years.)\n",
    "    df_combined_results.insert(0, 'Year', year)\n",
    "    \n",
    "    return df_combined_results\n",
    "\n",
    "def create_comparison_fields(df, field_var, year_list,\n",
    "                             field_year_separator = '_'):\n",
    "    '''This function calculates nominal and percentage changes\n",
    "    between the last year in a list and all years leading up to that year.\n",
    "    It also calculates both rank and percentile information for these\n",
    "    changes.\n",
    "    \n",
    "    df: the DataFrame that will be updated with comparisons between years.\n",
    "    This function assumes that the fields within df that contain \n",
    "    data for a particular year use the format\n",
    "    {field_var}{field_year_separator}{latest_year} (e.g. 'Total_Pop_2009', \n",
    "    'Total_Pop_2015', etc.). \n",
    "    \n",
    "    field_var: A string representing the variable \n",
    "    whose values should be compared (e.g. 'Total_Pop' within the field\n",
    "    'Total_Pop_2009'. \n",
    "\n",
    "    year_list: A list of years to compare. The function will compare\n",
    "    all years leading up to the last year with the last year. For example,\n",
    "    if year_list equals [2005, 2009, 2015], the function will create\n",
    "    comparisons between (1) 2005 and 2015 and (2) 2009 and 2015 (but not\n",
    "    2005 and 2009).\n",
    "    field_var data for each of these years should be stored within\n",
    "    the DataFrame. For instance, if year_list is equal to the example\n",
    "    shown above, field_var is 'Total_Pop', and field_year_separator (see\n",
    "    below) is '_', the script will expect to see the following fields\n",
    "    within the DataFrame:\n",
    "    'Total_Pop_2005', 'Total_Pop_2009', 'Total_Pop_2015'\n",
    "\n",
    "    field_year_separator: The character (e.g. a space, an underscore,\n",
    "    etc.) separating the field_var and year values within the DataFrame's\n",
    "    fields.\n",
    "    \n",
    "    '''\n",
    "    latest_year = year_list[-1]\n",
    "    for year in year_list[:-1]: # E.g. for all years leading up \n",
    "        # to (but not including) latest_year\n",
    "\n",
    "        # Calculating the nominal change between the two years:\n",
    "        df[f'{year}-{latest_year} {field_var} Change'] = (\n",
    "        df[f'{field_var}{field_year_separator}{latest_year}'] \n",
    "        - df[f'{field_var}{field_year_separator}{year}'] )\n",
    "\n",
    "        # Calculating the percentage change:\n",
    "        df[f'{year}-{latest_year} {field_var} % Change'] = 100*((\n",
    "        df[f'{field_var}{field_year_separator}{latest_year}'] \n",
    "        / df[f'{field_var}{field_year_separator}{year}']) - 1)\n",
    "\n",
    "    \n",
    "        # Calculating ranks and percentiles for both the nominal \n",
    "        # change and % change columns:\n",
    "        # Note that field_var still needs to be included within these\n",
    "        # columns in order to specify what change, exactly, is being\n",
    "        # analyzed. (This is particularly important when this function\n",
    "        # gets called for multiple field_var entries.)\n",
    "        df[f'{year}-{latest_year} {field_var} Change Rank'] = df[\n",
    "        f'{year}-{latest_year} {field_var} Change'].rank(\n",
    "            ascending=False, method = 'min')\n",
    "        \n",
    "        df[f'{year}-{latest_year} {field_var} Change Percentile'] = (\n",
    "        100 * df[\n",
    "        f'{year}-{latest_year} {field_var} Change'].rank(\n",
    "            pct=True, ascending=True, method='max'))\n",
    "        \n",
    "        df[f'{year}-{latest_year} {field_var} % Change Rank'] = (\n",
    "            df[f'{year}-{latest_year} {field_var} % Change'].rank(\n",
    "            ascending=False, method = 'min'))\n",
    "        \n",
    "        df[f'{year}-{latest_year} {field_var} % Change Percentile'] = (\n",
    "            100 * df[\n",
    "            f'{year}-{latest_year} {field_var} % Change'].rank(\n",
    "            pct=True, ascending=True, method='max'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
