{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae086d03-43a3-432e-a7bf-a289e4f0f365",
   "metadata": {},
   "source": [
    "# Descriptive Stats: Part 2\n",
    "\n",
    "By Kenneth Burchfiel \n",
    "\n",
    "This second part of Python for Nonprofits' descriptive stats section covers several potential data analysis pitfalls. Specifically, it will explore:\n",
    "\n",
    "1. How to adjust for missing values when calculating weighted averages\n",
    "1. The risk of relying on column index positions\n",
    "1. Why column-wise operations should be preferred over for loops\n",
    "1. Challenges with finding average values for fields whose rows are themselves averages\n",
    "1. Methods of accounting for missing data when creating pivot tables\n",
    "1. Issues with using `np.where()` to create derivatives of columns with missing data (and why `map()` and `np.select()` are better fits)\n",
    "\n",
    "I have to admit that, even by programming textbook standards, you may not find this to be the most exciting chapter. You may well be anxious to get ahead to the graphing, mapping, and online dashboard sections of PFN--i.e. the 'fun' stuff. \n",
    "\n",
    "However, in order to be confident that your graphs, maps, and dashboards will provide an accurate view of your underlying data, it's crucial to exercise caution when pivoting and transforming tables. This chapter is meant to help you be more cautious--and thus more successful--in your data analysis adventures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98e1126f-9ae5-421d-b500-7114d1ebe2aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:23.830269Z",
     "iopub.status.busy": "2025-03-22T17:51:23.830072Z",
     "iopub.status.idle": "2025-03-22T17:51:24.080915Z",
     "shell.execute_reply": "2025-03-22T17:51:24.080535Z",
     "shell.execute_reply.started": "2025-03-22T17:51:23.830257Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "e = create_engine('sqlite:///../Appendix/nvcu_db.db')\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../Appendix')\n",
    "from helper_funcs import config_notebook\n",
    "display_type = config_notebook(display_max_columns=6,\n",
    "                              display_max_rows=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524d4cad-4b1b-4ffc-ac53-3584de8563a3",
   "metadata": {},
   "source": [
    "## Calculating weighted average results by student (and dealing with missing values)\n",
    "\n",
    "Suppose that the NVCU administration also wishes to see what percentage of students had a weighted average annual survey score below 60. Because they are more interested in students' most recent survey results, they would like you to assign a weight of 0.2 to the fall results; 0.3 to the winter results; and 0.5 to the spring results. (Thus, students' weighted survey averages will equal 0.2\\*F + 0.3\\*W + 0.5\\*S, with F, W, and S referring to students' fall, winter, and spring results, respectively.)\n",
    "\n",
    "We'll begin this analysis by loading in 'survey_results_by_student_wide.csv', which shows fall, winter, and spring scores side by side for each student."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18854455-6f89-41a5-974d-ad48e164db14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:24.081330Z",
     "iopub.status.busy": "2025-03-22T17:51:24.081188Z",
     "iopub.status.idle": "2025-03-22T17:51:24.100905Z",
     "shell.execute_reply": "2025-03-22T17:51:24.100655Z",
     "shell.execute_reply.started": "2025-03-22T17:51:24.081320Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starting_year</th>\n",
       "      <th>student_id</th>\n",
       "      <th>Fall</th>\n",
       "      <th>Winter</th>\n",
       "      <th>Spring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>2020-1</td>\n",
       "      <td>88.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>2020-10</td>\n",
       "      <td>69.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>2020-100</td>\n",
       "      <td>68.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>2020-1000</td>\n",
       "      <td>58.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023</td>\n",
       "      <td>2020-1001</td>\n",
       "      <td>88.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   starting_year student_id  Fall  Winter  Spring\n",
       "0           2023     2020-1  88.0    81.0    86.0\n",
       "1           2023    2020-10  69.0    63.0    73.0\n",
       "2           2023   2020-100  68.0    60.0    88.0\n",
       "3           2023  2020-1000  58.0    55.0    65.0\n",
       "4           2023  2020-1001  88.0    84.0   100.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_student_results_wide = pd.read_csv(\n",
    "    'survey_results_by_student_wide.csv')\n",
    "# Creating a copy of this DataFrame that includes only students with \n",
    "# valid winter survey results:\n",
    "# (We'll make use of this copy later within this notebook.)\n",
    "df_valid_survey_results = (\n",
    "    df_student_results_wide.query(\"Winter.notna()\").copy().drop(\n",
    "        'starting_year', axis=1))\n",
    "df_student_results_wide.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bdd2ae-3b2e-4c11-9c26-84f6b6c11185",
   "metadata": {},
   "source": [
    "Because not all students took the winter survey, some winter results have NaN (not a number) values. We can count the number of NaN results for each column by (1) calling the `isna()` function, which displays whether or not each cell is NaN, then (2) following that call with .sum() in order to add up all NaN entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07c6ae75-41e7-4252-bf23-d05d3dffc6d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:24.101832Z",
     "iopub.status.busy": "2025-03-22T17:51:24.101668Z",
     "iopub.status.idle": "2025-03-22T17:51:24.105429Z",
     "shell.execute_reply": "2025-03-22T17:51:24.105129Z",
     "shell.execute_reply.started": "2025-03-22T17:51:24.101822Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "starting_year       0\n",
       "student_id          0\n",
       "Fall                0\n",
       "Winter           2458\n",
       "Spring              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_student_results_wide.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57711012-ce83-441b-a128-7ef1e0446504",
   "metadata": {},
   "source": [
    "These missing results will make our weighted average calculations a bit more complicated. For instance, suppose we tried to create our weighted averages using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f6cef0c-f93b-4538-902d-8330563d1940",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:24.105953Z",
     "iopub.status.busy": "2025-03-22T17:51:24.105752Z",
     "iopub.status.idle": "2025-03-22T17:51:24.107632Z",
     "shell.execute_reply": "2025-03-22T17:51:24.107394Z",
     "shell.execute_reply.started": "2025-03-22T17:51:24.105941Z"
    }
   },
   "outputs": [],
   "source": [
    "avg_score_cols_to_display = [\n",
    "    'student_id', 'Fall', 'Winter', 'Spring', 'weighted_avg_score'] \n",
    "# Displaying only these columns in the following cells will help\n",
    "# condense the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8acf2e9-bf55-48f8-a89c-b071100e212a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:24.108097Z",
     "iopub.status.busy": "2025-03-22T17:51:24.107925Z",
     "iopub.status.idle": "2025-03-22T17:51:24.114888Z",
     "shell.execute_reply": "2025-03-22T17:51:24.114632Z",
     "shell.execute_reply.started": "2025-03-22T17:51:24.108088Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>Fall</th>\n",
       "      <th>Winter</th>\n",
       "      <th>Spring</th>\n",
       "      <th>weighted_avg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-1</td>\n",
       "      <td>88.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>84.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10</td>\n",
       "      <td>69.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>69.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-100</td>\n",
       "      <td>68.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>75.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-1000</td>\n",
       "      <td>58.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>60.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-1001</td>\n",
       "      <td>88.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>92.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  student_id  Fall  Winter  Spring  weighted_avg_score\n",
       "0     2020-1  88.0    81.0    86.0                84.9\n",
       "1    2020-10  69.0    63.0    73.0                69.2\n",
       "2   2020-100  68.0    60.0    88.0                75.6\n",
       "3  2020-1000  58.0    55.0    65.0                60.6\n",
       "4  2020-1001  88.0    84.0   100.0                92.8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_student_results_wide['weighted_avg_score'] = (\n",
    "    df_student_results_wide['Fall'] * 0.2 \n",
    "    + df_student_results_wide['Winter'] * 0.3 \n",
    "    + df_student_results_wide['Spring'] * 0.5)\n",
    "df_student_results_wide[avg_score_cols_to_display].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0120fc1-bfde-4783-9072-09302663ad6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T02:14:17.398218Z",
     "iopub.status.busy": "2025-03-19T02:14:17.397880Z",
     "iopub.status.idle": "2025-03-19T02:14:17.408741Z",
     "shell.execute_reply": "2025-03-19T02:14:17.408221Z",
     "shell.execute_reply.started": "2025-03-19T02:14:17.398195Z"
    }
   },
   "source": [
    "This code works fine for students with valid scores for all 3 seasons, but those with a NaN winter value will also end up with a NaN average score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3004d0de-c67c-4863-901e-c3c70be222b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:24.115340Z",
     "iopub.status.busy": "2025-03-22T17:51:24.115234Z",
     "iopub.status.idle": "2025-03-22T17:51:24.122063Z",
     "shell.execute_reply": "2025-03-22T17:51:24.121802Z",
     "shell.execute_reply.started": "2025-03-22T17:51:24.115330Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>Fall</th>\n",
       "      <th>Winter</th>\n",
       "      <th>Spring</th>\n",
       "      <th>weighted_avg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020-1011</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2020-1025</td>\n",
       "      <td>69.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2020-1027</td>\n",
       "      <td>59.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2020-1047</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2020-105</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   student_id  Fall  Winter  Spring  weighted_avg_score\n",
       "15  2020-1011  85.0     NaN   100.0                 NaN\n",
       "30  2020-1025  69.0     NaN    65.0                 NaN\n",
       "32  2020-1027  59.0     NaN    71.0                 NaN\n",
       "54  2020-1047  64.0     NaN    82.0                 NaN\n",
       "57   2020-105  84.0     NaN    99.0                 NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_student_results_wide.query(\"Winter.isna()\")[\n",
    "avg_score_cols_to_display].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87b31ab-de50-4b8b-9460-4e1d80bc060a",
   "metadata": {},
   "source": [
    "A naive approach to compensate for these NaN results would be to call `fillna()` to replace all NaN values with 0, as shown in the following block of code. However, **this approach will result in inaccurately low average score values for students with missing winter results.** This is because our valid score weights for these students (0.2 for fall and 0.5 for spring) add up to only 0.7.\n",
    "\n",
    "In the following output, note how the weighted averages for students with missing winter scores are lower than both their fall *and* spring scores, which doesn't make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d1c5bdd-a155-464a-ab1b-1ce17e26a786",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:24.122592Z",
     "iopub.status.busy": "2025-03-22T17:51:24.122405Z",
     "iopub.status.idle": "2025-03-22T17:51:24.129689Z",
     "shell.execute_reply": "2025-03-22T17:51:24.129433Z",
     "shell.execute_reply.started": "2025-03-22T17:51:24.122582Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>Fall</th>\n",
       "      <th>Winter</th>\n",
       "      <th>Spring</th>\n",
       "      <th>weighted_avg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020-1011</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2020-1025</td>\n",
       "      <td>69.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.0</td>\n",
       "      <td>46.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2020-1027</td>\n",
       "      <td>59.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.0</td>\n",
       "      <td>47.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2020-1047</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>53.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2020-105</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.0</td>\n",
       "      <td>66.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   student_id  Fall  Winter  Spring  weighted_avg_score\n",
       "15  2020-1011  85.0     NaN   100.0                67.0\n",
       "30  2020-1025  69.0     NaN    65.0                46.3\n",
       "32  2020-1027  59.0     NaN    71.0                47.3\n",
       "54  2020-1047  64.0     NaN    82.0                53.8\n",
       "57   2020-105  84.0     NaN    99.0                66.3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_student_results_wide['weighted_avg_score'] = (\n",
    "    df_student_results_wide['Fall'].fillna(0) * 0.2 \n",
    "    + df_student_results_wide['Winter'].fillna(0) * 0.3 \n",
    "    + df_student_results_wide['Spring'].fillna(0) * 0.5)\n",
    "df_student_results_wide.query(\"Winter.isna()\")[\n",
    "avg_score_cols_to_display].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b98811-504f-4413-971c-0c7edf5f7535",
   "metadata": {},
   "source": [
    "Here's a better approach that, while a bit more complex, successfully adjusts for missing values. First, we'll create a weight column for each season that displays either our predetermined weight (if a student has a valid score for that season) or 0 (if the student does not). We'll also create a column that adds all of these weights together.\n",
    "\n",
    "The following code applies `np.where()` to determine whether or not to assign a given student/season pair a weight of 0. If a score is missing for a given season, that season will receive a weight entry of 0; otherwise, it will be assigned the usual weight. (See https://numpy.org/doc/stable/reference/generated/numpy.where.html for more information about np.where().)\n",
    "\n",
    "`np.where()` is a great option for filling in DataFrame fields based on two specific conditions (e.g. is survey data for a season *missing* or *present*?). However, if you ever need to handle three or more conditions, consider using `np.select()` instead. (We'll cover this function later within PFN.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11b0ccc2-9eba-45a0-b752-13c38ff9b2dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:24.130174Z",
     "iopub.status.busy": "2025-03-22T17:51:24.130007Z",
     "iopub.status.idle": "2025-03-22T17:51:24.139261Z",
     "shell.execute_reply": "2025-03-22T17:51:24.139046Z",
     "shell.execute_reply.started": "2025-03-22T17:51:24.130164Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starting_year</th>\n",
       "      <th>student_id</th>\n",
       "      <th>Fall</th>\n",
       "      <th>...</th>\n",
       "      <th>Winter_weight</th>\n",
       "      <th>Spring_weight</th>\n",
       "      <th>weight_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>2020-1</td>\n",
       "      <td>88.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>2020-10</td>\n",
       "      <td>69.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>2020-100</td>\n",
       "      <td>68.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>2020-1000</td>\n",
       "      <td>58.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023</td>\n",
       "      <td>2020-1001</td>\n",
       "      <td>88.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   starting_year student_id  Fall  ...  Winter_weight  Spring_weight  \\\n",
       "0           2023     2020-1  88.0  ...            0.3            0.5   \n",
       "1           2023    2020-10  69.0  ...            0.3            0.5   \n",
       "2           2023   2020-100  68.0  ...            0.3            0.5   \n",
       "3           2023  2020-1000  58.0  ...            0.3            0.5   \n",
       "4           2023  2020-1001  88.0  ...            0.3            0.5   \n",
       "\n",
       "   weight_sum  \n",
       "0         1.0  \n",
       "1         1.0  \n",
       "2         1.0  \n",
       "3         1.0  \n",
       "4         1.0  \n",
       "\n",
       "[5 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season_weight_dict = {'Fall':0.2,'Winter':0.3,'Spring':0.5}\n",
    "# Using a for loop to create these columns makes our code a bit more \n",
    "# concise.\n",
    "for season in ['Fall', 'Winter', 'Spring']:\n",
    "    df_student_results_wide[season+'_weight'] = np.where(\n",
    "        df_student_results_wide[season].isna(), 0, \n",
    "        season_weight_dict[season])    \n",
    "\n",
    "# adding axis=1 as an argument to df.sum() ensures that the calculations\n",
    "# will be made row-wise rather than column-wise.\n",
    "df_student_results_wide['weight_sum'] = df_student_results_wide[[\n",
    "    'Fall_weight', 'Winter_weight', 'Spring_weight']].sum(axis=1)\n",
    "\n",
    "df_student_results_wide.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0cd324-f21c-41d2-a840-70fc0b0aa017",
   "metadata": {},
   "source": [
    "We can now accurately calculate average scores for all students by (1) multiplying each score by its corresponding weight value (which will be 0 in the case of missing scores); (2) adding these products together; and then (3) dividing the sum by the `weight_sum` column. If a student has missing values for a given season, his or her `weight_sum` value will also be lower, thus compensating for his/her lower sum of scores.\n",
    "\n",
    "(Note that we'll still fill in missing scores with 0 in order to prevent final NaN outputs.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5061f75-592b-4d77-a8d3-633edb63e3cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:24.139662Z",
     "iopub.status.busy": "2025-03-22T17:51:24.139564Z",
     "iopub.status.idle": "2025-03-22T17:51:24.147995Z",
     "shell.execute_reply": "2025-03-22T17:51:24.147705Z",
     "shell.execute_reply.started": "2025-03-22T17:51:24.139653Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starting_year</th>\n",
       "      <th>student_id</th>\n",
       "      <th>Fall</th>\n",
       "      <th>...</th>\n",
       "      <th>Winter_weight</th>\n",
       "      <th>Spring_weight</th>\n",
       "      <th>weight_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023</td>\n",
       "      <td>2020-1011</td>\n",
       "      <td>85.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2023</td>\n",
       "      <td>2020-1025</td>\n",
       "      <td>69.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2023</td>\n",
       "      <td>2020-1027</td>\n",
       "      <td>59.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2023</td>\n",
       "      <td>2020-1047</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2023</td>\n",
       "      <td>2020-105</td>\n",
       "      <td>84.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    starting_year student_id  Fall  ...  Winter_weight  Spring_weight  \\\n",
       "15           2023  2020-1011  85.0  ...            0.0            0.5   \n",
       "30           2023  2020-1025  69.0  ...            0.0            0.5   \n",
       "32           2023  2020-1027  59.0  ...            0.0            0.5   \n",
       "54           2023  2020-1047  64.0  ...            0.0            0.5   \n",
       "57           2023   2020-105  84.0  ...            0.0            0.5   \n",
       "\n",
       "    weight_sum  \n",
       "15         0.7  \n",
       "30         0.7  \n",
       "32         0.7  \n",
       "54         0.7  \n",
       "57         0.7  \n",
       "\n",
       "[5 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_student_results_wide['weighted_avg_score'] = (\n",
    "    df_student_results_wide['Fall'].fillna(0) \n",
    "    * df_student_results_wide['Fall_weight']\n",
    "    + df_student_results_wide['Winter'].fillna(0) \n",
    "    * df_student_results_wide['Winter_weight']\n",
    "    + df_student_results_wide['Spring'].fillna(0)\n",
    "    * df_student_results_wide['Spring_weight']) / (\n",
    "        df_student_results_wide['weight_sum'])\n",
    "\n",
    "df_student_results_wide.query(\"Winter.isna()\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445cf672-60df-4292-b954-567a20861a10",
   "metadata": {},
   "source": [
    "The following output confirms that students' weighted average scores are no longer being dragged down by missing winter results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15784b0a-ca8b-49b6-8589-243b99ae2d98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:24.148524Z",
     "iopub.status.busy": "2025-03-22T17:51:24.148355Z",
     "iopub.status.idle": "2025-03-22T17:51:24.154876Z",
     "shell.execute_reply": "2025-03-22T17:51:24.154549Z",
     "shell.execute_reply.started": "2025-03-22T17:51:24.148513Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>Fall</th>\n",
       "      <th>Winter</th>\n",
       "      <th>Spring</th>\n",
       "      <th>weighted_avg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020-1011</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>95.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2020-1025</td>\n",
       "      <td>69.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.0</td>\n",
       "      <td>66.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2020-1027</td>\n",
       "      <td>59.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.0</td>\n",
       "      <td>67.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2020-1047</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>76.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2020-105</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.0</td>\n",
       "      <td>94.714286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   student_id  Fall  Winter  Spring  weighted_avg_score\n",
       "15  2020-1011  85.0     NaN   100.0           95.714286\n",
       "30  2020-1025  69.0     NaN    65.0           66.142857\n",
       "32  2020-1027  59.0     NaN    71.0           67.571429\n",
       "54  2020-1047  64.0     NaN    82.0           76.857143\n",
       "57   2020-105  84.0     NaN    99.0           94.714286"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_student_results_wide.query(\"Winter.isna()\")[\n",
    "avg_score_cols_to_display].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2353d88a-7c64-4dd2-9307-5fc622b368b8",
   "metadata": {},
   "source": [
    "A few additional notes:\n",
    "\n",
    "1. This approach would also successfully compensate for students with missing fall or spring scores. It would only fail to work for students who had no survey results at all--but such students should be excluded from these calculations to begin with.\n",
    "\n",
    "2. Note that, for students with missing winter weights, this code uses a fall score weight of 0.2/0.7 (28.6%) and a spring score weight of 0.5/0.7 (71.4%). Thus, fall and spring results counted more for these students than they did for students with valid winter results.\n",
    "\n",
    "Now that we've calculated weighted average results for all students, we can finally answer the administrators' original question: what percentage of students had a weigted average survey score below 60?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fdfa1ad-94c3-4e67-b494-87044b035ef4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:24.155534Z",
     "iopub.status.busy": "2025-03-22T17:51:24.155276Z",
     "iopub.status.idle": "2025-03-22T17:51:24.159185Z",
     "shell.execute_reply": "2025-03-22T17:51:24.158947Z",
     "shell.execute_reply.started": "2025-03-22T17:51:24.155522Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weighted_avg_below_60\n",
       "0    81.286621\n",
       "1    18.713379\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_student_results_wide['weighted_avg_below_60'] = np.where(\n",
    "    df_student_results_wide['weighted_avg_score'] < 60, 1, 0)\n",
    "\n",
    "# Calling value_counts(normalize=True), then multiplying the results \n",
    "# by 100, allows us to calculate the percentage of students with weighted \n",
    "# averages below 60.\n",
    "100*df_student_results_wide['weighted_avg_below_60'].value_counts(\n",
    "    normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5f67e2-fcd9-4139-a599-5bd99bac6f81",
   "metadata": {},
   "source": [
    "It turns out that around 18.7% of students had a weighted average score below 60."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676a51c9-07fd-42a3-ab3a-16d1b2e6d8c9",
   "metadata": {},
   "source": [
    "## The danger of relying on column index positions when analyzing datasets\n",
    "\n",
    "There are several different ways to specify the DataFrame columns on which you would like to perform operations. So far, I have been selecting columns using their names (e.g. `df_student_results_wide['Spring']`). However, it's also possible to select them via their index positions. In this section, I'll explain why this is often *not* a good idea."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a320815-249d-4cd6-ade4-6ebeb05b3f2d",
   "metadata": {},
   "source": [
    "`df_valid_survey_results`, a copy of our student-level results table that excludes missing winter results, has four columns: 'student_id', 'Fall', 'Winter', and 'Spring'. These columns' index positions are 0, 1, 2, and 3, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32159eb5-de9e-4117-b31b-44150c08d47b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:24.160792Z",
     "iopub.status.busy": "2025-03-22T17:51:24.160575Z",
     "iopub.status.idle": "2025-03-22T17:51:24.164857Z",
     "shell.execute_reply": "2025-03-22T17:51:24.164622Z",
     "shell.execute_reply.started": "2025-03-22T17:51:24.160781Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>Fall</th>\n",
       "      <th>Winter</th>\n",
       "      <th>Spring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-1</td>\n",
       "      <td>88.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10</td>\n",
       "      <td>69.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-100</td>\n",
       "      <td>68.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-1000</td>\n",
       "      <td>58.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-1001</td>\n",
       "      <td>88.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  student_id  Fall  Winter  Spring\n",
       "0     2020-1  88.0    81.0    86.0\n",
       "1    2020-10  69.0    63.0    73.0\n",
       "2   2020-100  68.0    60.0    88.0\n",
       "3  2020-1000  58.0    55.0    65.0\n",
       "4  2020-1001  88.0    84.0   100.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid_survey_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2309845e-36b8-4aa2-8f80-0ff8ccaefcc7",
   "metadata": {},
   "source": [
    "If I wanted to create a non-weighted average of students' winter and spring scores, I *could* use `.iloc[]` (which allows columns to be selected via these index positions) to retrieve the scores for these two seasons.\n",
    "\n",
    "In the following code, `.iloc[:,2:4]` selects all rows for the columns between index positions 2 (inclusive) and 4 (exclusive)--or, in other words, the columns with index positions 2 and 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f016e35-67d8-4a21-86d7-8182d1fc35c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:24.165273Z",
     "iopub.status.busy": "2025-03-22T17:51:24.165160Z",
     "iopub.status.idle": "2025-03-22T17:51:24.172895Z",
     "shell.execute_reply": "2025-03-22T17:51:24.172672Z",
     "shell.execute_reply.started": "2025-03-22T17:51:24.165264Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>Fall</th>\n",
       "      <th>Winter</th>\n",
       "      <th>Spring</th>\n",
       "      <th>Winter/Spring Avg.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-1</td>\n",
       "      <td>88.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>83.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10</td>\n",
       "      <td>69.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-100</td>\n",
       "      <td>68.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-1000</td>\n",
       "      <td>58.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16379</th>\n",
       "      <td>2023-995</td>\n",
       "      <td>84.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16381</th>\n",
       "      <td>2023-997</td>\n",
       "      <td>47.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16382</th>\n",
       "      <td>2023-998</td>\n",
       "      <td>77.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>70.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16383</th>\n",
       "      <td>2023-999</td>\n",
       "      <td>64.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>63.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13926 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      student_id  Fall  Winter  Spring  Winter/Spring Avg.\n",
       "0         2020-1  88.0    81.0    86.0                83.5\n",
       "1        2020-10  69.0    63.0    73.0                68.0\n",
       "2       2020-100  68.0    60.0    88.0                74.0\n",
       "3      2020-1000  58.0    55.0    65.0                60.0\n",
       "...          ...   ...     ...     ...                 ...\n",
       "16379   2023-995  84.0    79.0    85.0                82.0\n",
       "16381   2023-997  47.0    42.0    42.0                42.0\n",
       "16382   2023-998  77.0    67.0    74.0                70.5\n",
       "16383   2023-999  64.0    62.0    65.0                63.5\n",
       "\n",
       "[13926 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid_survey_results[\n",
    "'Winter/Spring Avg.'] = df_valid_survey_results.iloc[\n",
    ":,2:4].mean(axis=1)\n",
    "df_valid_survey_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb00436-8f10-4904-a917-a88409cd3e57",
   "metadata": {},
   "source": [
    "This code accurately calculates the average of each student's winter and spring survey scores. What makes it dangerous, though, is that a minor change to the table could end up filling this field with incorrect data.\n",
    "\n",
    "For instance, suppose that a new column gets added to the left of our survey scores in the future:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b57deefc-640a-4ec7-ac38-d29ed81bcf56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:24.173411Z",
     "iopub.status.busy": "2025-03-22T17:51:24.173201Z",
     "iopub.status.idle": "2025-03-22T17:51:24.178431Z",
     "shell.execute_reply": "2025-03-22T17:51:24.178155Z",
     "shell.execute_reply.started": "2025-03-22T17:51:24.173399Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>University</th>\n",
       "      <th>Fall</th>\n",
       "      <th>Winter</th>\n",
       "      <th>Spring</th>\n",
       "      <th>Winter/Spring Avg.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-1</td>\n",
       "      <td>NVCU</td>\n",
       "      <td>88.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>83.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10</td>\n",
       "      <td>NVCU</td>\n",
       "      <td>69.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-100</td>\n",
       "      <td>NVCU</td>\n",
       "      <td>68.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-1000</td>\n",
       "      <td>NVCU</td>\n",
       "      <td>58.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-1001</td>\n",
       "      <td>NVCU</td>\n",
       "      <td>88.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  student_id University  Fall  Winter  Spring  Winter/Spring Avg.\n",
       "0     2020-1       NVCU  88.0    81.0    86.0                83.5\n",
       "1    2020-10       NVCU  69.0    63.0    73.0                68.0\n",
       "2   2020-100       NVCU  68.0    60.0    88.0                74.0\n",
       "3  2020-1000       NVCU  58.0    55.0    65.0                60.0\n",
       "4  2020-1001       NVCU  88.0    84.0   100.0                92.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid_survey_results.insert(1, 'University', 'NVCU')\n",
    "df_valid_survey_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919760a9-889b-4b16-8dd7-bc0845ffc3dd",
   "metadata": {},
   "source": [
    "If we call the same code on this modified column, our 'Winter/Spring Avg.' column will now show the average of *fall* and winter scores, since the 'University' column has changed which columns correspond to the index positions of 2 and 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cee2ee2d-6c31-40ab-a5a1-62bf93b24459",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:24.178992Z",
     "iopub.status.busy": "2025-03-22T17:51:24.178748Z",
     "iopub.status.idle": "2025-03-22T17:51:24.185310Z",
     "shell.execute_reply": "2025-03-22T17:51:24.185063Z",
     "shell.execute_reply.started": "2025-03-22T17:51:24.178982Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>University</th>\n",
       "      <th>Fall</th>\n",
       "      <th>Winter</th>\n",
       "      <th>Spring</th>\n",
       "      <th>Winter/Spring Avg.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-1</td>\n",
       "      <td>NVCU</td>\n",
       "      <td>88.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>84.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10</td>\n",
       "      <td>NVCU</td>\n",
       "      <td>69.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-100</td>\n",
       "      <td>NVCU</td>\n",
       "      <td>68.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-1000</td>\n",
       "      <td>NVCU</td>\n",
       "      <td>58.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>56.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-1001</td>\n",
       "      <td>NVCU</td>\n",
       "      <td>88.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  student_id University  Fall  Winter  Spring  Winter/Spring Avg.\n",
       "0     2020-1       NVCU  88.0    81.0    86.0                84.5\n",
       "1    2020-10       NVCU  69.0    63.0    73.0                66.0\n",
       "2   2020-100       NVCU  68.0    60.0    88.0                64.0\n",
       "3  2020-1000       NVCU  58.0    55.0    65.0                56.5\n",
       "4  2020-1001       NVCU  88.0    84.0   100.0                86.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid_survey_results[\n",
    "'Winter/Spring Avg.'] = df_valid_survey_results.iloc[\n",
    ":,2:4].mean(axis=1)\n",
    "df_valid_survey_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43dc2b3-81f5-4c3c-afe4-5e1cb6a52bc3",
   "metadata": {},
   "source": [
    "Thus, a much safer approach is to explicitly name the columns that you wish to incorporate into a calculation. The following code will work fine regardless of the index positions of the 'Winter' and 'Spring' columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96d945c5-db03-4a75-9a79-846894410970",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:24.185785Z",
     "iopub.status.busy": "2025-03-22T17:51:24.185603Z",
     "iopub.status.idle": "2025-03-22T17:51:24.192304Z",
     "shell.execute_reply": "2025-03-22T17:51:24.192075Z",
     "shell.execute_reply.started": "2025-03-22T17:51:24.185774Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>University</th>\n",
       "      <th>Fall</th>\n",
       "      <th>Winter</th>\n",
       "      <th>Spring</th>\n",
       "      <th>Winter/Spring Avg.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-1</td>\n",
       "      <td>NVCU</td>\n",
       "      <td>88.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>83.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10</td>\n",
       "      <td>NVCU</td>\n",
       "      <td>69.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-100</td>\n",
       "      <td>NVCU</td>\n",
       "      <td>68.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-1000</td>\n",
       "      <td>NVCU</td>\n",
       "      <td>58.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-1001</td>\n",
       "      <td>NVCU</td>\n",
       "      <td>88.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  student_id University  Fall  Winter  Spring  Winter/Spring Avg.\n",
       "0     2020-1       NVCU  88.0    81.0    86.0                83.5\n",
       "1    2020-10       NVCU  69.0    63.0    73.0                68.0\n",
       "2   2020-100       NVCU  68.0    60.0    88.0                74.0\n",
       "3  2020-1000       NVCU  58.0    55.0    65.0                60.0\n",
       "4  2020-1001       NVCU  88.0    84.0   100.0                92.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid_survey_results[\n",
    "'Winter/Spring Avg.'] = df_valid_survey_results[\n",
    "['Winter', 'Spring']].mean(axis=1)\n",
    "df_valid_survey_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b19dcd7-870d-4762-ab07-af7d0e92a3b3",
   "metadata": {},
   "source": [
    "Note that the code that explicitly states the name of each column is also more intuitive, as it eliminates the need to cross-reference which column corresponds to each index position. And the more intuitive you can keep your code, particularly within complex projects, the better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b34706-04fb-447b-9d0a-c07ec0cb591e",
   "metadata": {},
   "source": [
    "## Why column-wise operations should be preferred over for loops\n",
    "\n",
    "If you're a newcomer to Pandas, you may initially want to try using for loops to update values within DataFrames (especially if you've been used to using such loops within languages like C or C++). However, I recommend that you use *column-wise operations* (e.g. code that will apply to all rows within a column) rather than loops whenever possible, simply because the former are much, much faster than the latter.\n",
    "\n",
    "Let's say that we wanted to create an unweighted average of our fall, winter, and spring scores within `df_valid_survey_results`. One option would be to initialize an empty 'Average' column, then fill it in by looping through all rows in our dataset.\n",
    "\n",
    "Creating our 'Average' column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f070a822-38b8-4e76-a2fe-10e71fe8f29e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:24.192697Z",
     "iopub.status.busy": "2025-03-22T17:51:24.192595Z",
     "iopub.status.idle": "2025-03-22T17:51:24.198142Z",
     "shell.execute_reply": "2025-03-22T17:51:24.197907Z",
     "shell.execute_reply.started": "2025-03-22T17:51:24.192687Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>Fall</th>\n",
       "      <th>Winter</th>\n",
       "      <th>Spring</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-1</td>\n",
       "      <td>88.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10</td>\n",
       "      <td>69.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-100</td>\n",
       "      <td>68.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-1000</td>\n",
       "      <td>58.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-1001</td>\n",
       "      <td>88.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  student_id  Fall  Winter  Spring  Average\n",
       "0     2020-1  88.0    81.0    86.0      NaN\n",
       "1    2020-10  69.0    63.0    73.0      NaN\n",
       "2   2020-100  68.0    60.0    88.0      NaN\n",
       "3  2020-1000  58.0    55.0    65.0      NaN\n",
       "4  2020-1001  88.0    84.0   100.0      NaN"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing columns that we no longer need:\n",
    "df_valid_survey_results.drop(\n",
    "    ['University', 'Winter/Spring Avg.'], axis=1, inplace=True)\n",
    "df_valid_survey_results['Average'] = np.nan\n",
    "df_valid_survey_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d690468-ec03-4de9-8646-44febacc25d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T04:27:50.323058Z",
     "iopub.status.busy": "2025-03-22T04:27:50.322060Z",
     "iopub.status.idle": "2025-03-22T04:27:50.331023Z",
     "shell.execute_reply": "2025-03-22T04:27:50.330667Z",
     "shell.execute_reply.started": "2025-03-22T04:27:50.322983Z"
    }
   },
   "source": [
    "Determining the index position of our 'Average' column: \n",
    "\n",
    "(If we tried to use this column's name within our for loop rather than its index position, the averages wouldn't actually get added in, and we'd end up with a `SettingWithCopyWarning`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e76a7b96-53e5-48ab-9836-69657d5eccb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:24.198659Z",
     "iopub.status.busy": "2025-03-22T17:51:24.198457Z",
     "iopub.status.idle": "2025-03-22T17:51:24.201005Z",
     "shell.execute_reply": "2025-03-22T17:51:24.200731Z",
     "shell.execute_reply.started": "2025-03-22T17:51:24.198649Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_index = df_valid_survey_results.columns.get_loc('Average')\n",
    "avg_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ae12e1-1a38-4d07-b136-0d3e91be7c97",
   "metadata": {},
   "source": [
    "Calculating this average for each row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9d89db2-b499-432f-9ccd-b5f58b6c6cbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:24.201553Z",
     "iopub.status.busy": "2025-03-22T17:51:24.201353Z",
     "iopub.status.idle": "2025-03-22T17:51:25.969569Z",
     "shell.execute_reply": "2025-03-22T17:51:25.969233Z",
     "shell.execute_reply.started": "2025-03-22T17:51:24.201544Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>Fall</th>\n",
       "      <th>Winter</th>\n",
       "      <th>Spring</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-1</td>\n",
       "      <td>88.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>85.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10</td>\n",
       "      <td>69.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>68.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-100</td>\n",
       "      <td>68.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-1000</td>\n",
       "      <td>58.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>59.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-1001</td>\n",
       "      <td>88.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>90.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  student_id  Fall  Winter  Spring    Average\n",
       "0     2020-1  88.0    81.0    86.0  85.000000\n",
       "1    2020-10  69.0    63.0    73.0  68.333333\n",
       "2   2020-100  68.0    60.0    88.0  72.000000\n",
       "3  2020-1000  58.0    55.0    65.0  59.333333\n",
       "4  2020-1001  88.0    84.0   100.0  90.666667"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(df_valid_survey_results)):\n",
    "    df_valid_survey_results.iloc[i, avg_index] = (\n",
    "    # Note: the following alternative to the previous line would not work,\n",
    "    # as noted in the documentation above:\n",
    "    # df_valid_survey_results.iloc[i]['Average'] = (  # Incorrect!\n",
    "        df_valid_survey_results.iloc[i]['Fall'] + \n",
    "        df_valid_survey_results.iloc[i]['Winter'] + \n",
    "        df_valid_survey_results.iloc[i]['Spring']) / 3\n",
    "df_valid_survey_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec09b271-d285-42d0-b8b8-7197428f3d07",
   "metadata": {},
   "source": [
    "I ran the previous cell 5 times on my computer and found that it took an average of 1.72 seconds to execute. There are 13,926 rows within `df_valid_survey_results`, so even on a fast laptop, it will take Python a decent while to process each one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa71910d-629c-4dbe-b380-5a8e19b45503",
   "metadata": {},
   "source": [
    "The following cell, in contrast, uses a column-wise operation to compute this average:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8f1a4e5-755f-4d92-aabb-45dc2afe4b9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:25.970088Z",
     "iopub.status.busy": "2025-03-22T17:51:25.969957Z",
     "iopub.status.idle": "2025-03-22T17:51:25.975670Z",
     "shell.execute_reply": "2025-03-22T17:51:25.975429Z",
     "shell.execute_reply.started": "2025-03-22T17:51:25.970079Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>Fall</th>\n",
       "      <th>Winter</th>\n",
       "      <th>Spring</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-1</td>\n",
       "      <td>88.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>85.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10</td>\n",
       "      <td>69.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>68.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-100</td>\n",
       "      <td>68.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-1000</td>\n",
       "      <td>58.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>59.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-1001</td>\n",
       "      <td>88.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>90.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  student_id  Fall  Winter  Spring    Average\n",
       "0     2020-1  88.0    81.0    86.0  85.000000\n",
       "1    2020-10  69.0    63.0    73.0  68.333333\n",
       "2   2020-100  68.0    60.0    88.0  72.000000\n",
       "3  2020-1000  58.0    55.0    65.0  59.333333\n",
       "4  2020-1001  88.0    84.0   100.0  90.666667"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid_survey_results['Average'] = (\n",
    "    df_valid_survey_results['Fall'] + \n",
    "    df_valid_survey_results['Winter'] + \n",
    "    df_valid_survey_results['Spring']) / 3\n",
    "df_valid_survey_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1463a6-09cd-480f-87b1-9bb6a4c515b5",
   "metadata": {},
   "source": [
    "I ran this cell 5 times as well and found that it needed only 5.4 milliseconds (on average) to execute. In other words, it was over *300 times* faster than the for loop-based approach!\n",
    "\n",
    "The difference between 1.72 seconds and 0.006 seconds may not seem like much in nominal terms. However, when you're dealing with a dataset that contains 13 *million* rows rather than 13 *thousand*, or a script that performs dozens of these sorts of calculations, the performance advantage of column-wise calculations will become much clearer.\n",
    "\n",
    "There are many ways to execute even complex calculations in column-wise form; tools like `np.where()`, `np.select()`, `Series.map()`, and `Series.apply()` can help you do so."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcde4e40-47ef-412c-b80f-a9c67ec3de99",
   "metadata": {},
   "source": [
    "## Microdata, pre-baked data, and the 'average of averages' problem\n",
    "\n",
    "`df_transactions`, a table of NVCU dining hall transactions that the following cell loads in, is an excellent candidate for creating a diverse set of pivot tables and charts because each transaction has its own row. (In other words, the table contains *microdata*; for more on this subject, reference https://en.wikipedia.org/wiki/Microdata_(statistics) .) Microdata-based tables allow you to easily calculate statistics for your choice of comparison variables by (1) grouping rows into unique combinations of these variables, then (2) applying one or more statistical functions (`mean`, `median`, etc.) to each group. (As you've already seen, pivot tables make this process very simple.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34d86f85-0c95-4f21-a4c6-45460242eb97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:25.976092Z",
     "iopub.status.busy": "2025-03-22T17:51:25.975993Z",
     "iopub.status.idle": "2025-03-22T17:51:26.012032Z",
     "shell.execute_reply": "2025-03-22T17:51:26.011757Z",
     "shell.execute_reply.started": "2025-03-22T17:51:25.976082Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starting_year</th>\n",
       "      <th>weekday</th>\n",
       "      <th>level</th>\n",
       "      <th>amount</th>\n",
       "      <th>transactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>We</td>\n",
       "      <td>Fr</td>\n",
       "      <td>13.36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>Tu</td>\n",
       "      <td>Se</td>\n",
       "      <td>12.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>We</td>\n",
       "      <td>Se</td>\n",
       "      <td>23.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>Su</td>\n",
       "      <td>Fr</td>\n",
       "      <td>18.78</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023</td>\n",
       "      <td>Tu</td>\n",
       "      <td>Fr</td>\n",
       "      <td>11.36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   starting_year weekday level  amount  transactions\n",
       "0           2023      We    Fr   13.36             1\n",
       "1           2023      Tu    Se   12.22             1\n",
       "2           2023      We    Se   23.10             1\n",
       "3           2023      Su    Fr   18.78             1\n",
       "4           2023      Tu    Fr   11.36             1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions = pd.read_sql(\n",
    "    'select * from dining_transactions', con=e)\n",
    "df_transactions['transactions'] = 1\n",
    "df_transactions.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1c29e0-0c86-49bf-9857-55ec43439bcb",
   "metadata": {},
   "source": [
    "If you wanted to calculate the average dining hall transaction amount, you could simply find the mean of all items within this table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08e5f2e1-bd87-407a-a5b8-a83553f8d051",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:26.012524Z",
     "iopub.status.busy": "2025-03-22T17:51:26.012369Z",
     "iopub.status.idle": "2025-03-22T17:51:26.015006Z",
     "shell.execute_reply": "2025-03-22T17:51:26.014764Z",
     "shell.execute_reply.started": "2025-03-22T17:51:26.012513Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(12.65563577250256)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions['amount'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7193e8f0-cdce-413f-a173-f8d6daea647c",
   "metadata": {},
   "source": [
    "If you instead wanted to find the average amount spent by *weekday and level*, you could easily do so via Pandas' `pivot_table()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "368f34e4-2ccb-46f3-b62d-0fbffa150ad1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:26.015422Z",
     "iopub.status.busy": "2025-03-22T17:51:26.015320Z",
     "iopub.status.idle": "2025-03-22T17:51:26.025355Z",
     "shell.execute_reply": "2025-03-22T17:51:26.025107Z",
     "shell.execute_reply.started": "2025-03-22T17:51:26.015412Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekday</th>\n",
       "      <th>level</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Su</td>\n",
       "      <td>Se</td>\n",
       "      <td>22.426887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>We</td>\n",
       "      <td>Se</td>\n",
       "      <td>21.550155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mo</td>\n",
       "      <td>Se</td>\n",
       "      <td>21.346364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Tu</td>\n",
       "      <td>Se</td>\n",
       "      <td>21.268938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Th</td>\n",
       "      <td>Se</td>\n",
       "      <td>21.072613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weekday level     amount\n",
       "14      Su    Se  22.426887\n",
       "26      We    Se  21.550155\n",
       "6       Mo    Se  21.346364\n",
       "22      Tu    Se  21.268938\n",
       "18      Th    Se  21.072613"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions.pivot_table(\n",
    "    index=['weekday', 'level'], values='amount', \n",
    "    aggfunc='mean').reset_index().sort_values(\n",
    "    by='amount', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddfd5d6-1f5b-4928-850c-aa4cf14c5e97",
   "metadata": {},
   "source": [
    "However, you may not always have access to this type of data. Instead, you might receive an *aggregated* dataset in which averages by different groups are *pre-baked*--e.g. already present in the output. As you'll soon see, this makes the table much less flexible.\n",
    "\n",
    "'pre-baked' is not, to my knowledge, a common statistical term, but I find that it works pretty well for describing this type of data. For instance, once you've *baked* a pie using apples, wheat, and sugar (or whatever goes into a pie--I'm not a baker!), it's pretty hard to convert that dish into a caramelized apple. Similarly, as the following examples will show, once you've 'baked' a list of transactions into separate sets of averages by level and by weekday, it will be impossible to use that data to calculate total spending amounts by level *and* weekday--as we no longer know how each level value relates to each weekday value.\n",
    "\n",
    "To illustrate this issues caused by pre-baked datasets, let's generate two DataFrames, the first of which will show average transaction amounts by level, and the second of which will show average amounts by weekday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23024958-78ae-4a1d-aaae-d8d9240a4084",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:26.025839Z",
     "iopub.status.busy": "2025-03-22T17:51:26.025698Z",
     "iopub.status.idle": "2025-03-22T17:51:26.034324Z",
     "shell.execute_reply": "2025-03-22T17:51:26.033894Z",
     "shell.execute_reply.started": "2025-03-22T17:51:26.025829Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>amount</th>\n",
       "      <th>transactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fr</td>\n",
       "      <td>9.911620</td>\n",
       "      <td>12410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ju</td>\n",
       "      <td>17.133287</td>\n",
       "      <td>3289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Se</td>\n",
       "      <td>21.294252</td>\n",
       "      <td>2046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So</td>\n",
       "      <td>13.006451</td>\n",
       "      <td>4708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  level     amount  transactions\n",
       "0    Fr   9.911620         12410\n",
       "1    Ju  17.133287          3289\n",
       "2    Se  21.294252          2046\n",
       "3    So  13.006451          4708"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_average_spending_by_level = df_transactions.pivot_table(\n",
    "    index='level', values=[\n",
    "    'amount', 'transactions'], aggfunc={\n",
    "    'amount':'mean', 'transactions':'count'}).reset_index()\n",
    "df_average_spending_by_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cfc5f9b9-0eee-416d-8cf8-51681e1445da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:26.034938Z",
     "iopub.status.busy": "2025-03-22T17:51:26.034795Z",
     "iopub.status.idle": "2025-03-22T17:51:26.049038Z",
     "shell.execute_reply": "2025-03-22T17:51:26.047333Z",
     "shell.execute_reply.started": "2025-03-22T17:51:26.034925Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekday</th>\n",
       "      <th>amount</th>\n",
       "      <th>transactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fr</td>\n",
       "      <td>12.721265</td>\n",
       "      <td>2466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mo</td>\n",
       "      <td>12.632190</td>\n",
       "      <td>3608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sa</td>\n",
       "      <td>12.253912</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Su</td>\n",
       "      <td>12.775699</td>\n",
       "      <td>1123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Th</td>\n",
       "      <td>12.592931</td>\n",
       "      <td>3964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tu</td>\n",
       "      <td>12.747500</td>\n",
       "      <td>5267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>We</td>\n",
       "      <td>12.624990</td>\n",
       "      <td>5317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  weekday     amount  transactions\n",
       "0      Fr  12.721265          2466\n",
       "1      Mo  12.632190          3608\n",
       "2      Sa  12.253912           708\n",
       "3      Su  12.775699          1123\n",
       "4      Th  12.592931          3964\n",
       "5      Tu  12.747500          5267\n",
       "6      We  12.624990          5317"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_average_spending_by_weekday = df_transactions.pivot_table(\n",
    "    index='weekday', values=[\n",
    "    'amount', 'transactions'], aggfunc={\n",
    "    'amount':'mean', 'transactions':'count'}).reset_index()\n",
    "df_average_spending_by_weekday"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb413868-ae05-4c14-a63a-d7d5100de2fb",
   "metadata": {},
   "source": [
    "We can see that lower levels (e.g. freshmen and sophomores) tend to spend less per dining hall visit than upper levels; in addition, we can see that spending doesn't vary too much by day of the week. However, because these tables are pre-baked, we don't have any way of calculating average spending by level *and* weekday like we could with df_transactions. \n",
    "\n",
    "In addition, let's say that we wanted to calculate average dining hall spending for all students using `df_average_spending_by_level`. A naive approach would be to simply calculate the average of each row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da2dd436-c873-47b7-88b4-9d67b2384dd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:26.049873Z",
     "iopub.status.busy": "2025-03-22T17:51:26.049676Z",
     "iopub.status.idle": "2025-03-22T17:51:26.055488Z",
     "shell.execute_reply": "2025-03-22T17:51:26.055042Z",
     "shell.execute_reply.started": "2025-03-22T17:51:26.049854Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(15.336402324109617)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following approach is incorrect:\n",
    "\n",
    "df_average_spending_by_level['amount'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886f2e7f-c9ca-44e4-b28e-c797f9e10cf6",
   "metadata": {},
   "source": [
    "This average is way off the actual average, which we calculated earlier in this code using `df_transactions`. Why is this the case? As `df_average_spending_by_level` shows, seniors and juniors spend much more than freshmen and sophomores, yet they also use the dining hall less (as shown by their smaller transaction counts). As a result, if we simply average the mean transaction amounts for each level, we'll overrepresent upperclassmen and thus skew our average transaction amount upward.\n",
    "\n",
    "In order to avoid this 'average of averages' issue, which arises whenever differences in group sizes skew an average that's in turn based on averages for those groups, we'll need to create a *weighted* average. We can do so by multiplying each row's 'amount' column by its 'transaction' column; adding these products together; and then dividing them by the 'transaction' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75a905ac-fa83-4fa0-8590-fa165477e07d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:26.056408Z",
     "iopub.status.busy": "2025-03-22T17:51:26.056223Z",
     "iopub.status.idle": "2025-03-22T17:51:26.063399Z",
     "shell.execute_reply": "2025-03-22T17:51:26.062954Z",
     "shell.execute_reply.started": "2025-03-22T17:51:26.056390Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>amount</th>\n",
       "      <th>transactions</th>\n",
       "      <th>amount_x_transactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fr</td>\n",
       "      <td>9.911620</td>\n",
       "      <td>12410</td>\n",
       "      <td>123003.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ju</td>\n",
       "      <td>17.133287</td>\n",
       "      <td>3289</td>\n",
       "      <td>56351.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Se</td>\n",
       "      <td>21.294252</td>\n",
       "      <td>2046</td>\n",
       "      <td>43568.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So</td>\n",
       "      <td>13.006451</td>\n",
       "      <td>4708</td>\n",
       "      <td>61234.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  level     amount  transactions  amount_x_transactions\n",
       "0    Fr   9.911620         12410              123003.20\n",
       "1    Ju  17.133287          3289               56351.38\n",
       "2    Se  21.294252          2046               43568.04\n",
       "3    So  13.006451          4708               61234.37"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_average_spending_by_level['amount_x_transactions'] = (\n",
    "    df_average_spending_by_level['amount'] \n",
    "    * df_average_spending_by_level['transactions'])\n",
    "df_average_spending_by_level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddac54da-87b4-49ee-b059-e6866e04f82f",
   "metadata": {},
   "source": [
    "Here's our weighted average, which matches the average calculated earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "917ba5f3-7f66-42c6-8839-d8054f1129e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:26.064104Z",
     "iopub.status.busy": "2025-03-22T17:51:26.063930Z",
     "iopub.status.idle": "2025-03-22T17:51:26.067585Z",
     "shell.execute_reply": "2025-03-22T17:51:26.067144Z",
     "shell.execute_reply.started": "2025-03-22T17:51:26.064088Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(12.65563577250256)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_average_spending_by_level['amount_x_transactions'].sum() \n",
    " / df_average_spending_by_level['transactions'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f6cddb-f361-47d8-b14c-d00bde395538",
   "metadata": {},
   "source": [
    "The following function can be used to calculate weighted means for other datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c82203e-46d8-471b-89cd-4f70c495638e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:26.068091Z",
     "iopub.status.busy": "2025-03-22T17:51:26.067956Z",
     "iopub.status.idle": "2025-03-22T17:51:26.070508Z",
     "shell.execute_reply": "2025-03-22T17:51:26.070192Z",
     "shell.execute_reply.started": "2025-03-22T17:51:26.068080Z"
    }
   },
   "outputs": [],
   "source": [
    "def weighted_mean(original_df, metric_col, weight_col):\n",
    "    '''This function calculates, then returns, a weighted mean for\n",
    "    the DataFrame passed to original_df.\n",
    "    metric_col: the column storing the variable for which to calculate\n",
    "    a mean.\n",
    "    weight_col: the column storing weight values that will be incorporated\n",
    "    into this weighted mean.    \n",
    "    '''\n",
    "    df = original_df.copy() # Prevents the function from modifying\n",
    "    # the original DataFrame\n",
    "    df['metric_x_weight'] = df[metric_col] * df[weight_col]\n",
    "    weighted_mean = (df['metric_x_weight'].sum() / \n",
    "    df[weight_col].sum())\n",
    "    return weighted_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b645bc6-5d68-45ba-85c6-378a4ce96e1b",
   "metadata": {},
   "source": [
    "Let's try putting this function into action by calculating the average transaction amount using df_average_spending_by_weekday:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31f5f212-ca5b-414e-9021-a73afc7ca11d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:26.071012Z",
     "iopub.status.busy": "2025-03-22T17:51:26.070837Z",
     "iopub.status.idle": "2025-03-22T17:51:26.074115Z",
     "shell.execute_reply": "2025-03-22T17:51:26.073867Z",
     "shell.execute_reply.started": "2025-03-22T17:51:26.071001Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(12.65563577250256)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_mean(df_average_spending_by_weekday, \n",
    "                 metric_col='amount',\n",
    "                 weight_col='transactions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6803eb-acd8-4e7a-a2f6-31cdc8266940",
   "metadata": {},
   "source": [
    "This average matches the weighted average that we calculated within `df_average_spending_by_level`. \n",
    "\n",
    "Incidentally, because average transaction amounts are relatively constant across weekdays, simply averaging all 'amount' values within `df_average_spending_by_weekday` will get us very close to the actual average (despite the considerable variation in transaction counts by weekday). These kinds of 'believable', yet incorrect values are particularly insidious: they may go unnoticed for quite a while, whereas an obviously incorrect value (e.g. an average transaction amount of -5 or 83,000) would get caught right away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "951738c3-38d5-4216-beb9-487bfba8c02b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:26.074518Z",
     "iopub.status.busy": "2025-03-22T17:51:26.074421Z",
     "iopub.status.idle": "2025-03-22T17:51:26.076971Z",
     "shell.execute_reply": "2025-03-22T17:51:26.076735Z",
     "shell.execute_reply.started": "2025-03-22T17:51:26.074509Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(12.621212399856491)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_average_spending_by_weekday['amount'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ef2d30-2564-48bd-be4d-e6df890f03d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-22T03:01:34.093172Z",
     "iopub.status.busy": "2025-01-22T03:01:34.091840Z",
     "iopub.status.idle": "2025-01-22T03:01:34.097099Z",
     "shell.execute_reply": "2025-01-22T03:01:34.096691Z",
     "shell.execute_reply.started": "2025-01-22T03:01:34.093107Z"
    }
   },
   "source": [
    "We were able to calculate correct averages within these pre-baked tables because we also knew the number of transactions within each row. In the real world, though, such sample size information may not be available.\n",
    "\n",
    "From a data analysis perspective, it would be ideal to have all of your source data in microdata (rather than pre-baked) form. However, the microdata approach has its own drawbacks. \n",
    "\n",
    "First, data privacy needs may preclude the issuance of microdata. Imagine, for instance, that NVCU released a dataset that contained individual course grades for each student along with those students' majors. If you happened to be the only music major who took a C++ course, anyone with that knowledge could find out how you performed in the class. \n",
    "\n",
    "A more private approach, in this case, would be to release separate 'pre-baked' tables that showed averages for courses and by major (but not averages for each course/major pair). (Even with this strategy, if a given pre-baked average was based on only a few students, it might be best to remove that row's data so as to protect those students' privacy.)\n",
    "\n",
    "Second, microdata can take up much more storage size than pre-baked data. To illustrate this, let's compare the amount of memory, in kilobytes, used by `df_transactions` (a microdata-based table) with that used by our two pre-baked tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4123e936-36fb-45c6-aa29-db443f6f952b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:26.077358Z",
     "iopub.status.busy": "2025-03-22T17:51:26.077265Z",
     "iopub.status.idle": "2025-03-22T17:51:26.089714Z",
     "shell.execute_reply": "2025-03-22T17:51:26.089369Z",
     "shell.execute_reply.started": "2025-03-22T17:51:26.077348Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2829.21)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "microdata_kb = df_transactions.memory_usage(\n",
    "    index = True, deep = True).sum() / 1000\n",
    "# For more on df.memory_usage(), see\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/\n",
    "# pandas.DataFrame.memory_usage.html\n",
    "microdata_kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d9d74ff0-506d-4716-8837-7c9e99e67aa9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:26.090336Z",
     "iopub.status.busy": "2025-03-22T17:51:26.090174Z",
     "iopub.status.idle": "2025-03-22T17:51:26.094255Z",
     "shell.execute_reply": "2025-03-22T17:51:26.094015Z",
     "shell.execute_reply.started": "2025-03-22T17:51:26.090319Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.033)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_baked_kb = (df_average_spending_by_level.memory_usage(\n",
    "    index = True, deep = True).sum() + \n",
    " df_average_spending_by_weekday.memory_usage(\n",
    "    index = True, deep = True).sum()) / 1000\n",
    "pre_baked_kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7a01c77-022d-4779-948e-26ed56f329b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:26.094722Z",
     "iopub.status.busy": "2025-03-22T17:51:26.094609Z",
     "iopub.status.idle": "2025-03-22T17:51:26.097887Z",
     "shell.execute_reply": "2025-03-22T17:51:26.097627Z",
     "shell.execute_reply.started": "2025-03-22T17:51:26.094712Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2738.828654404647)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "microdata_kb / pre_baked_kb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08aee637-7439-4ab3-b3f3-2e1d1a667f37",
   "metadata": {},
   "source": [
    "The microdata table takes up over 2,700 times more memory than our two pre-baked tables combined! Therefore, it's understandable that data providers may prefer to share pre-calculated averages rather than original datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3e7992-68e8-4712-87ff-2a79413e8e23",
   "metadata": {},
   "source": [
    "## Handling missing data when creating pivot tables\n",
    "\n",
    "If a field passed to the `index` or `columns` argument of a `pivot_table()` call has a missing value, that missing value won't get incorporated into the final table. This can cause calculation errors if you end up using the pivot table for further analyses. However, mitigating this issue isn't too difficult.\n",
    "\n",
    "To demonstrate this issue, I'll create a 'faulty' version of `df_transactions` in the following cell that has `np.nan` (i.e.. missing) entries for all 'Wednesday' weekday values and all 'So' level values. As you'll see, these missing values will cause issues when we (1) create a pivot table of this data, then (2) attempt to use that pivot table to determine the sum of all transactions in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29bed734-b8c3-434c-bacd-3b697be53be8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:26.098482Z",
     "iopub.status.busy": "2025-03-22T17:51:26.098235Z",
     "iopub.status.idle": "2025-03-22T17:51:26.107074Z",
     "shell.execute_reply": "2025-03-22T17:51:26.106793Z",
     "shell.execute_reply.started": "2025-03-22T17:51:26.098471Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starting_year</th>\n",
       "      <th>weekday</th>\n",
       "      <th>level</th>\n",
       "      <th>amount</th>\n",
       "      <th>transactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fr</td>\n",
       "      <td>13.36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>Tu</td>\n",
       "      <td>Se</td>\n",
       "      <td>12.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Se</td>\n",
       "      <td>23.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>Su</td>\n",
       "      <td>Fr</td>\n",
       "      <td>18.78</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023</td>\n",
       "      <td>Tu</td>\n",
       "      <td>Fr</td>\n",
       "      <td>11.36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   starting_year weekday level  amount  transactions\n",
       "0           2023     NaN    Fr   13.36             1\n",
       "1           2023      Tu    Se   12.22             1\n",
       "2           2023     NaN    Se   23.10             1\n",
       "3           2023      Su    Fr   18.78             1\n",
       "4           2023      Tu    Fr   11.36             1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Passing the 'level' and 'weekday' fields as the final arguments\n",
    "# within these function calls allows these fields' original\n",
    "# values to get retained should the conditions in the first \n",
    "# arguments not be met. (For instance, in the first np.where()\n",
    "# call, Wednesday values will get replaced with missing entries,\n",
    "# but non-Wednesday values will get replaced with themselves\n",
    "# (thus leaving them unchanged).\n",
    "\n",
    "df_transactions_faulty = df_transactions.copy()\n",
    "df_transactions_faulty['weekday'] = np.where(\n",
    "    df_transactions_faulty['weekday'] == 'We', \n",
    "np.nan, df_transactions_faulty['weekday']) \n",
    "df_transactions_faulty['level'] = np.where(\n",
    "    df_transactions_faulty['level'] == 'So', \n",
    "np.nan, df_transactions_faulty['level']) \n",
    "\n",
    "df_transactions_faulty.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81b022a-b7a0-40f8-a705-01be2f170288",
   "metadata": {},
   "source": [
    "First, let's try converting this dataset into a pivot table that shows total transaction amounts by week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "caf1f04c-d0fa-4027-9f07-828c6d073049",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:26.107558Z",
     "iopub.status.busy": "2025-03-22T17:51:26.107415Z",
     "iopub.status.idle": "2025-03-22T17:51:26.114912Z",
     "shell.execute_reply": "2025-03-22T17:51:26.114652Z",
     "shell.execute_reply.started": "2025-03-22T17:51:26.107544Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekday</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fr</td>\n",
       "      <td>31370.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mo</td>\n",
       "      <td>45576.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sa</td>\n",
       "      <td>8675.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Su</td>\n",
       "      <td>14347.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Th</td>\n",
       "      <td>49918.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tu</td>\n",
       "      <td>67141.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  weekday    amount\n",
       "0      Fr  31370.64\n",
       "1      Mo  45576.94\n",
       "2      Sa   8675.77\n",
       "3      Su  14347.11\n",
       "4      Th  49918.38\n",
       "5      Tu  67141.08"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions_faulty_pivot = df_transactions_faulty.pivot_table(\n",
    "    index='weekday', values='amount', \n",
    "    aggfunc='sum').reset_index()\n",
    "df_transactions_faulty_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d10d2a-69e4-4b2b-81ec-446f37cfd7fd",
   "metadata": {},
   "source": [
    "There's no sign whatsoever of the 'Wednesday' rows. This shouldn't be too surprising (since we removed those values), but it's worth highlighting that no 'Missing' or 'N/A' row gets returned by the pivot table function.\n",
    "\n",
    "The complete absence of the 'Wednesday' row makes this this missing data issue easier to identify. However, many cases of missing data are far more insidious. For instance, suppose only a handful of 'Wednesday' entries were missing. We'd see a 'Wednesday' row within the pivot table, but we might not realize that its 'amount' sum was incorrect. (For this reason, it's often a good idea to check for missing entries within any fields that you pass to the `index` or `column` arguments of a `pivot_table()` call.)\n",
    "\n",
    "If we try to use this pivot table to calculate the sum of all our transactions, we'll end up with an incorrect result, since rows with missing 'weekday' values won't factor into the calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7d8c0504-b042-443f-8273-4ae074889199",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:26.115351Z",
     "iopub.status.busy": "2025-03-22T17:51:26.115244Z",
     "iopub.status.idle": "2025-03-22T17:51:26.117625Z",
     "shell.execute_reply": "2025-03-22T17:51:26.117365Z",
     "shell.execute_reply.started": "2025-03-22T17:51:26.115341Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(217029.91999999998)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions_faulty_pivot['amount'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dcac59-aa4c-49b6-9aab-c8f208db1b36",
   "metadata": {},
   "source": [
    "For reference, here's the correct sum (that also includes Wednesday transactions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "709b8620-2cd3-495e-b714-6d18a48da4f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:26.118057Z",
     "iopub.status.busy": "2025-03-22T17:51:26.117952Z",
     "iopub.status.idle": "2025-03-22T17:51:26.120632Z",
     "shell.execute_reply": "2025-03-22T17:51:26.120326Z",
     "shell.execute_reply.started": "2025-03-22T17:51:26.118047Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(284156.99)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions['amount'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cb9f25-cd25-442f-b3ee-5b8c180f1148",
   "metadata": {},
   "source": [
    "Thankfully, it's not too hard to prevent this issue. We simply need to fill in missing values within any fields fields passed to the `index` or `columns` arguments of the `pivot_table()` call.\n",
    "\n",
    "I'll demonstrate two ways to replace these values with a 'Missing' string. First, if you don't wish to permanently modify your original DataFrame, you can call `.fillna()` on the DataFrame being passed to the `pivot_table()` function. This ensures that rows with missing data get incorporated into the pivot table but leaves the original DataFrame untouched. \n",
    "\n",
    "The following code implements this approach via a *dict comprehension*. (For more on this valuable tool, see https://docs.python.org/3/tutorial/datastructures.html#dictionaries .) This approach allows me to use the same list of `index` values that I'll pass to `pivot_table()` to specify which columns' missing entries should get filled in. This results in cleaner and less error-prone code, as if I needed to update my index values twice, once for `pivot_table()` and once for `fillna()`, the two lists could easily get out of sync.\n",
    "\n",
    "The pivot table we'll create in the following cell will show total transactions by both level and weekday, but a similar method would work for tables that show sums for only one of these two groups.\n",
    "\n",
    "(Another option, by the way, would be to fill missing entries within *all* columns with a 'Missing' string; this could be accomplished via `df_transactions_faulty.fillna('Missing')`. However, if some columns with missing data use float or integer types, this approach could either raise a warning or an error--as you'd be attempting to pass a string into a list of missing values. Thus, I recommend using the more precise solution shown below.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2e383b8a-6361-4d72-8c40-61629840ad3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:26.122866Z",
     "iopub.status.busy": "2025-03-22T17:51:26.122643Z",
     "iopub.status.idle": "2025-03-22T17:51:26.135948Z",
     "shell.execute_reply": "2025-03-22T17:51:26.135667Z",
     "shell.execute_reply.started": "2025-03-22T17:51:26.122855Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>weekday</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fr</td>\n",
       "      <td>Fr</td>\n",
       "      <td>13183.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fr</td>\n",
       "      <td>Missing</td>\n",
       "      <td>28856.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fr</td>\n",
       "      <td>Mo</td>\n",
       "      <td>20214.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fr</td>\n",
       "      <td>Sa</td>\n",
       "      <td>3739.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fr</td>\n",
       "      <td>Su</td>\n",
       "      <td>6230.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  level  weekday    amount\n",
       "0    Fr       Fr  13183.14\n",
       "1    Fr  Missing  28856.95\n",
       "2    Fr       Mo  20214.29\n",
       "3    Fr       Sa   3739.85\n",
       "4    Fr       Su   6230.97"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = ['level', 'weekday'] # These values will get passed to the\n",
    "# index argument of our pivot_table() call.\n",
    "# The following dict comprehension will produce the dictionary\n",
    "# {'level': 'Missing', 'weekday': 'Missing'}--which, when passed to\n",
    "# fillna(), will instruct Pandas to fill in missing data with 'Missing' \n",
    "# only within those two fields.\n",
    "# (For more on this argument, see\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/\n",
    "# api/pandas.DataFrame.fillna.html )\n",
    "df_transactions_corrected_pivot = df_transactions_faulty.fillna(\n",
    "    {field:'Missing' for field in index}).pivot_table(\n",
    "    index=index, values='amount',\n",
    "    aggfunc='sum').reset_index()\n",
    "df_transactions_corrected_pivot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10f5f9e-2668-4f30-a33f-cc929f20f8d2",
   "metadata": {},
   "source": [
    "Filling in missing 'level' and 'weekday' rows with 'Missing' allowed them to appear within our updated pivot table. As a result, we can now produce an accurate sum of all transactions by adding up the 'amount' rows within this table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "20fb2820-687a-4d42-b7d3-b31e6d106bb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:26.136509Z",
     "iopub.status.busy": "2025-03-22T17:51:26.136292Z",
     "iopub.status.idle": "2025-03-22T17:51:26.138744Z",
     "shell.execute_reply": "2025-03-22T17:51:26.138517Z",
     "shell.execute_reply.started": "2025-03-22T17:51:26.136497Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(284156.99)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions_corrected_pivot['amount'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05744d75-1ab0-479a-a1b7-2ae714bb3501",
   "metadata": {},
   "source": [
    "The following approach, unlike the one shown above, permanently replaces missing weekday and level values with 'Missing', thus saving you the trouble of repeating this step later in your code. It also iterates through each field in the `index` list via a for loop in order to inform you which columns, in particular, have missing data. \n",
    "\n",
    "In some cases, it may be preferable for your code to halt upon finding missing data; this halt serves as an alert that missing data exists, thus prompting you to fill in those missing entries with their actual values. The commented-out code above the first print statement in the following cell would stop this script's operation (by raising a `ValueError`) if it came across any missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b9d89bf0-627f-4001-a276-de5f8e0fa923",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:26.139233Z",
     "iopub.status.busy": "2025-03-22T17:51:26.139050Z",
     "iopub.status.idle": "2025-03-22T17:51:26.152906Z",
     "shell.execute_reply": "2025-03-22T17:51:26.152630Z",
     "shell.execute_reply.started": "2025-03-22T17:51:26.139222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level has NaN values; these will be filled with 'Missing' so that their rows' data can still get incorporated into the following pivot table.\n",
      "\n",
      "weekday has NaN values; these will be filled with 'Missing' so that their rows' data can still get incorporated into the following pivot table.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>weekday</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fr</td>\n",
       "      <td>Fr</td>\n",
       "      <td>13183.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fr</td>\n",
       "      <td>Missing</td>\n",
       "      <td>28856.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fr</td>\n",
       "      <td>Mo</td>\n",
       "      <td>20214.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fr</td>\n",
       "      <td>Sa</td>\n",
       "      <td>3739.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Se</td>\n",
       "      <td>Sa</td>\n",
       "      <td>1260.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Se</td>\n",
       "      <td>Su</td>\n",
       "      <td>2377.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Se</td>\n",
       "      <td>Th</td>\n",
       "      <td>7017.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Se</td>\n",
       "      <td>Tu</td>\n",
       "      <td>10613.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   level  weekday    amount\n",
       "0     Fr       Fr  13183.14\n",
       "1     Fr  Missing  28856.95\n",
       "2     Fr       Mo  20214.29\n",
       "3     Fr       Sa   3739.85\n",
       "..   ...      ...       ...\n",
       "24    Se       Sa   1260.53\n",
       "25    Se       Su   2377.25\n",
       "26    Se       Th   7017.18\n",
       "27    Se       Tu  10613.20\n",
       "\n",
       "[28 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for val in index:\n",
    "    if df_transactions_faulty[val].isna().sum() > 0:\n",
    "#         raise ValueError(f\"{val} has NaN values; address these before \\\n",
    "# running the following pivot table operation.\")\n",
    "        print(f\"{val} has NaN values; these will be filled with 'Missing' \\\n",
    "so that their rows' data can still get incorporated into the following \\\n",
    "pivot table.\\n\")\n",
    "        df_transactions_faulty[val] = df_transactions_faulty[val].fillna(\n",
    "            'Missing').copy()\n",
    "        # If a column with missing data was float-based rather than\n",
    "        # string-based, it would be best to enter a float-based missing\n",
    "        # data indicator rather than this string.\n",
    "        \n",
    "df_transactions_corrected_pivot = df_transactions_faulty.pivot_table(\n",
    "    index=index, values='amount',\n",
    "    aggfunc='sum').reset_index()\n",
    "df_transactions_corrected_pivot\n",
    "                         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a1dba5-3c6e-4fb1-9139-4bc4bf9f384b",
   "metadata": {},
   "source": [
    "This new version of `df_transactions_corrected_pivot` also lets us calculate an accurate sum of all transactions within the original dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d8ee828-2aa8-44ed-9937-4a6d378c8493",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:26.153492Z",
     "iopub.status.busy": "2025-03-22T17:51:26.153230Z",
     "iopub.status.idle": "2025-03-22T17:51:26.155628Z",
     "shell.execute_reply": "2025-03-22T17:51:26.155382Z",
     "shell.execute_reply.started": "2025-03-22T17:51:26.153481Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(284156.99)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions_corrected_pivot['amount'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979885a5-7fd2-4438-b38f-27ddec965a44",
   "metadata": {},
   "source": [
    "I'll now undo my corrections to df_transactions_faulty in order to prepare the dataset for the following section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1becdbba-2043-419e-99bf-02217906e1fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:26.156085Z",
     "iopub.status.busy": "2025-03-22T17:51:26.155915Z",
     "iopub.status.idle": "2025-03-22T17:51:26.163764Z",
     "shell.execute_reply": "2025-03-22T17:51:26.163491Z",
     "shell.execute_reply.started": "2025-03-22T17:51:26.156075Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starting_year</th>\n",
       "      <th>weekday</th>\n",
       "      <th>level</th>\n",
       "      <th>amount</th>\n",
       "      <th>transactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fr</td>\n",
       "      <td>13.36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>Tu</td>\n",
       "      <td>Se</td>\n",
       "      <td>12.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Se</td>\n",
       "      <td>23.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>Su</td>\n",
       "      <td>Fr</td>\n",
       "      <td>18.78</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22449</th>\n",
       "      <td>2023</td>\n",
       "      <td>Tu</td>\n",
       "      <td>Fr</td>\n",
       "      <td>5.98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22450</th>\n",
       "      <td>2023</td>\n",
       "      <td>Fr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22451</th>\n",
       "      <td>2023</td>\n",
       "      <td>Sa</td>\n",
       "      <td>Fr</td>\n",
       "      <td>13.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22452</th>\n",
       "      <td>2023</td>\n",
       "      <td>Mo</td>\n",
       "      <td>Fr</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22453 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       starting_year weekday level  amount  transactions\n",
       "0               2023     NaN    Fr   13.36             1\n",
       "1               2023      Tu    Se   12.22             1\n",
       "2               2023     NaN    Se   23.10             1\n",
       "3               2023      Su    Fr   18.78             1\n",
       "...              ...     ...   ...     ...           ...\n",
       "22449           2023      Tu    Fr    5.98             1\n",
       "22450           2023      Fr   NaN    7.39             1\n",
       "22451           2023      Sa    Fr   13.25             1\n",
       "22452           2023      Mo    Fr    1.95             1\n",
       "\n",
       "[22453 rows x 5 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions_faulty.replace(\n",
    "    'Missing', np.nan, inplace=True)\n",
    "df_transactions_faulty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80080f6e-a49b-4c31-9430-195b65806c48",
   "metadata": {},
   "source": [
    "## The advantages of `map()` and `np.select()` over `np.where()` when missing data are present\n",
    "\n",
    "Suppose we'd like to find the total number of dining hall transactions that took place on the weekend versus those that didn't. To make this calculation easier, we can add a 'weekday' column that will store a value of 1 if a transaction fell on Saturday or Sunday and 0 otherwise. \n",
    "\n",
    "We could try initializing this column via `np.where()`. The following cell uses this function to assign a 'weekend' value of 0 to all transactions whose 'weekday' value corresponds to Monday, Tuesday, Wednesday, Thursday, or Friday. Transactions that don't have one of these weekday values are classified as weekend sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2a0ce594-ab64-49ff-be26-f3a315b4cacd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:26.164305Z",
     "iopub.status.busy": "2025-03-22T17:51:26.164093Z",
     "iopub.status.idle": "2025-03-22T17:51:26.171025Z",
     "shell.execute_reply": "2025-03-22T17:51:26.170739Z",
     "shell.execute_reply.started": "2025-03-22T17:51:26.164294Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starting_year</th>\n",
       "      <th>weekday</th>\n",
       "      <th>level</th>\n",
       "      <th>amount</th>\n",
       "      <th>transactions</th>\n",
       "      <th>weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fr</td>\n",
       "      <td>13.36</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>Tu</td>\n",
       "      <td>Se</td>\n",
       "      <td>12.22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Se</td>\n",
       "      <td>23.10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>Su</td>\n",
       "      <td>Fr</td>\n",
       "      <td>18.78</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22449</th>\n",
       "      <td>2023</td>\n",
       "      <td>Tu</td>\n",
       "      <td>Fr</td>\n",
       "      <td>5.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22450</th>\n",
       "      <td>2023</td>\n",
       "      <td>Fr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22451</th>\n",
       "      <td>2023</td>\n",
       "      <td>Sa</td>\n",
       "      <td>Fr</td>\n",
       "      <td>13.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22452</th>\n",
       "      <td>2023</td>\n",
       "      <td>Mo</td>\n",
       "      <td>Fr</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22453 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       starting_year weekday level  amount  transactions  weekend\n",
       "0               2023     NaN    Fr   13.36             1        1\n",
       "1               2023      Tu    Se   12.22             1        0\n",
       "2               2023     NaN    Se   23.10             1        1\n",
       "3               2023      Su    Fr   18.78             1        1\n",
       "...              ...     ...   ...     ...           ...      ...\n",
       "22449           2023      Tu    Fr    5.98             1        0\n",
       "22450           2023      Fr   NaN    7.39             1        0\n",
       "22451           2023      Sa    Fr   13.25             1        1\n",
       "22452           2023      Mo    Fr    1.95             1        0\n",
       "\n",
       "[22453 rows x 6 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions_faulty['weekend'] = np.where(\n",
    "    df_transactions_faulty['weekday'].isin(\n",
    "        ['Mo', 'Tu', 'We', 'Th', 'Fr']), 0, 1)\n",
    "df_transactions_faulty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72765745-8cf5-4b6a-b956-d7320ec158cc",
   "metadata": {},
   "source": [
    "The issue with this approach, as you might have recognized already, is that it classifies all transactions with missing 'weekday' values as taking place during the weekend. We know that this is inaccurate: the transactions with missing weekday entries actually took place on Wednesday. (In real life, of course, we wouldn't know this to be the case--but we still wouldn't want to assume that they fell on the weekend.)\n",
    "\n",
    "Here is the total number of Saturday and Sunday dining hall transactions according to our 'weekend' column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8f08a8d4-de5e-4609-ad5d-691370585e1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:26.171585Z",
     "iopub.status.busy": "2025-03-22T17:51:26.171374Z",
     "iopub.status.idle": "2025-03-22T17:51:26.175716Z",
     "shell.execute_reply": "2025-03-22T17:51:26.175428Z",
     "shell.execute_reply.started": "2025-03-22T17:51:26.171570Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7148"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_transactions_faulty.query(\"weekend == 1\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d6c242-3970-49a6-9575-ded3e2e37fa9",
   "metadata": {},
   "source": [
    "As it turns out, this sum much higher than the correct value (which we can calculate using our original transactions table):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d608abf2-c25e-4add-ae3b-bed6c0f7ab15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:26.176124Z",
     "iopub.status.busy": "2025-03-22T17:51:26.176024Z",
     "iopub.status.idle": "2025-03-22T17:51:26.179977Z",
     "shell.execute_reply": "2025-03-22T17:51:26.179726Z",
     "shell.execute_reply.started": "2025-03-22T17:51:26.176115Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1831"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_transactions.query(\"weekday in ['Sa', 'Su']\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e45de8-634a-4b33-b234-52cbd91f7709",
   "metadata": {},
   "source": [
    "Let's now overwrite this faulty 'weekend' column by using `map()` instead. This function will allow us to map each individual weekday value to either 1 (for weekend) entries or 0 (for non-weekend values). Importantly, it also lets us map NaN entries to a third number, -1, which will represent missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4b505a40-2420-470f-9127-27211ecd41f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:26.180357Z",
     "iopub.status.busy": "2025-03-22T17:51:26.180261Z",
     "iopub.status.idle": "2025-03-22T17:51:26.186756Z",
     "shell.execute_reply": "2025-03-22T17:51:26.186509Z",
     "shell.execute_reply.started": "2025-03-22T17:51:26.180348Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starting_year</th>\n",
       "      <th>weekday</th>\n",
       "      <th>level</th>\n",
       "      <th>amount</th>\n",
       "      <th>transactions</th>\n",
       "      <th>weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fr</td>\n",
       "      <td>13.36</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>Tu</td>\n",
       "      <td>Se</td>\n",
       "      <td>12.22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Se</td>\n",
       "      <td>23.10</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>Su</td>\n",
       "      <td>Fr</td>\n",
       "      <td>18.78</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22449</th>\n",
       "      <td>2023</td>\n",
       "      <td>Tu</td>\n",
       "      <td>Fr</td>\n",
       "      <td>5.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22450</th>\n",
       "      <td>2023</td>\n",
       "      <td>Fr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22451</th>\n",
       "      <td>2023</td>\n",
       "      <td>Sa</td>\n",
       "      <td>Fr</td>\n",
       "      <td>13.25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22452</th>\n",
       "      <td>2023</td>\n",
       "      <td>Mo</td>\n",
       "      <td>Fr</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22453 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       starting_year weekday level  amount  transactions  weekend\n",
       "0               2023     NaN    Fr   13.36             1       -1\n",
       "1               2023      Tu    Se   12.22             1        0\n",
       "2               2023     NaN    Se   23.10             1       -1\n",
       "3               2023      Su    Fr   18.78             1        1\n",
       "...              ...     ...   ...     ...           ...      ...\n",
       "22449           2023      Tu    Fr    5.98             1        0\n",
       "22450           2023      Fr   NaN    7.39             1        0\n",
       "22451           2023      Sa    Fr   13.25             1        1\n",
       "22452           2023      Mo    Fr    1.95             1        0\n",
       "\n",
       "[22453 rows x 6 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions_faulty['weekend'] = (\n",
    "    df_transactions_faulty['weekday'].map(\n",
    "    {'Su':0, 'Mo':0, 'Tu': 0, 'We':0, 'Th':0, 'Fr':0, 'Sa':1, 'Su':1,\n",
    "     np.nan:-1}))\n",
    "df_transactions_faulty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d28e0c-f813-4af0-9847-2a99000bacb7",
   "metadata": {},
   "source": [
    "If we apply value_counts() to this column, we'll find that our weekend transactions count matches that shown above. The sum for the -1 entry shows the number of transactions that are missing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "74e49791-5f89-4470-86db-7188f3218c8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:26.187299Z",
     "iopub.status.busy": "2025-03-22T17:51:26.187073Z",
     "iopub.status.idle": "2025-03-22T17:51:26.190086Z",
     "shell.execute_reply": "2025-03-22T17:51:26.189804Z",
     "shell.execute_reply.started": "2025-03-22T17:51:26.187288Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weekend\n",
       " 0    15305\n",
       "-1     5317\n",
       " 1     1831\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions_faulty['weekend'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a3c86b-1188-4c90-9e64-cc9c285ff224",
   "metadata": {},
   "source": [
    "I could have also chosen to use 'Missing' as my marker for invalid data; however, since the other values output by `map()` were integers, I wanted to make the missing data code an integer also.\n",
    "\n",
    "As an aside, the use of 1 for weekend transactions and 0 for work-week ones makes it easy to determine the percentage of transactions that took place over the weekend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5a5d46d4-7cc4-498d-a67b-dcedb55f1e5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:26.190611Z",
     "iopub.status.busy": "2025-03-22T17:51:26.190378Z",
     "iopub.status.idle": "2025-03-22T17:51:26.194539Z",
     "shell.execute_reply": "2025-03-22T17:51:26.194255Z",
     "shell.execute_reply.started": "2025-03-22T17:51:26.190600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.69% of transactions with valid weekday entries took place on a Saturday or Sunday.\n"
     ]
    }
   ],
   "source": [
    "print(f\"{\n",
    "round(100*df_transactions_faulty.query(\n",
    "    \"weekend != -1\")['weekend'].mean(), 2)}% of transactions with valid \\\n",
    "weekday entries took place on a Saturday or Sunday.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9de6ed6-bed3-42da-802c-1da34f51af2e",
   "metadata": {},
   "source": [
    "Note the 'with valid weekday entries' caveat in the above print statement. Since we wouldn't know for sure on which weekdays the missing transactions took place, we wouldn't want our statement to make any assertionss about them.\n",
    "\n",
    "It was also crucial to exclude rows with weekend values of -1 from our above calculation. If we had kept them in, we would have ended up with a nonsensical percentage of weekend transactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e57bc73e-8160-4975-ad52-f4aca0369c61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:26.195060Z",
     "iopub.status.busy": "2025-03-22T17:51:26.194862Z",
     "iopub.status.idle": "2025-03-22T17:51:26.197097Z",
     "shell.execute_reply": "2025-03-22T17:51:26.196797Z",
     "shell.execute_reply.started": "2025-03-22T17:51:26.195047Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-15.53% of transactions took place on a Saturday or Sunday . . . wait, really? I think I need to double-check these numbers . . . \n"
     ]
    }
   ],
   "source": [
    "print(f\"{round(100 * df_transactions_faulty['weekend'].mean(), 2)}% \\\n",
    "of transactions took place on a Saturday or Sunday . . . wait, really? \\\n",
    "I think I need to double-check these numbers . . . \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505024f2-56df-4d9d-a7ea-f19920bc2bb8",
   "metadata": {},
   "source": [
    "If you're categorizing continuous rather than categorical data, the `map()` approach above will be hard to implement--as you might end up having to code a ton of values. Therefore, you should consider using `np.select()` instead. This function generally involves a bit more code than `map()` for categorical data, but it easily accommodates continuous values as well.\n",
    "\n",
    "Let's say that we want to add a 'large_purchase' flag to each row that will equal 1 if the amount was at or above the 90th percentile and 0 otherwise. We could then use this flag to determine each level's likelihood of making such a large purchase.\n",
    "\n",
    "The 90th percentile can be calculated as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3d434da6-b99a-43e1-ab0c-f60a46baa808",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:26.197529Z",
     "iopub.status.busy": "2025-03-22T17:51:26.197421Z",
     "iopub.status.idle": "2025-03-22T17:51:26.201037Z",
     "shell.execute_reply": "2025-03-22T17:51:26.200788Z",
     "shell.execute_reply.started": "2025-03-22T17:51:26.197519Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(24.067999999999994)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_purchase_threshold = df_transactions['amount'].quantile(0.9)\n",
    "# See https://pandas.pydata.org/docs/reference/api/\n",
    "# pandas.DataFrame.quantile.html\n",
    "large_purchase_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda6617a-d734-46f8-b0e0-b322b3247bf9",
   "metadata": {},
   "source": [
    "The following code will simplify `df_transactions_faulty` by removing some columns that won't be needed for the following section. It will also introduce missing numerical data by replacing all transactions whose final digit is a 6 with NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "db16ddb3-3cbe-41ee-9aaa-c06c5531cf5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:26.201602Z",
     "iopub.status.busy": "2025-03-22T17:51:26.201341Z",
     "iopub.status.idle": "2025-03-22T17:51:26.219610Z",
     "shell.execute_reply": "2025-03-22T17:51:26.219330Z",
     "shell.execute_reply.started": "2025-03-22T17:51:26.201591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starting_year</th>\n",
       "      <th>level</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>Fr</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>Se</td>\n",
       "      <td>12.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>Se</td>\n",
       "      <td>23.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>Fr</td>\n",
       "      <td>18.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023</td>\n",
       "      <td>Fr</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   starting_year level  amount\n",
       "0           2023    Fr     NaN\n",
       "1           2023    Se   12.22\n",
       "2           2023    Se   23.10\n",
       "3           2023    Fr   18.78\n",
       "4           2023    Fr     NaN"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions_faulty = df_transactions.copy().drop(\n",
    "    ['weekday', 'transactions'], \n",
    "    axis=1)\n",
    "\n",
    "df_transactions_faulty['amount'] = np.where(\n",
    "    df_transactions_faulty['amount'].astype('str').str[-1] == '6', \n",
    "    np.nan, df_transactions_faulty['amount'])\n",
    "\n",
    "df_transactions_faulty.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12121662-0a1d-43e0-b63e-674044d83fdf",
   "metadata": {},
   "source": [
    "We wouldn't want to use `np.where()` to initialize our 'large_purchase' column, as we would inadvertently group missing transactions as large or non-large. In addition, `map()` would be a poor solution, as we now have thousands of unique values to code rather than just a few:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "97f57144-5d24-48b5-ae9f-5db2c2ccf461",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:26.220207Z",
     "iopub.status.busy": "2025-03-22T17:51:26.219955Z",
     "iopub.status.idle": "2025-03-22T17:51:26.222539Z",
     "shell.execute_reply": "2025-03-22T17:51:26.222272Z",
     "shell.execute_reply.started": "2025-03-22T17:51:26.220196Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3131"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_transactions_faulty['amount'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d53b208-bcaa-4578-8e8f-aa6923d93243",
   "metadata": {},
   "source": [
    "Therefore, we'll instead use `np.select()`. This function applies a `condlist` (a list of possible conditions) and a `choicelist` (a list of values to apply for each of those conditions) in order to initialize or update a given column. (You don't have to name these items `condlist` and `choicelist`, but those are their corresponding parameter names; see https://numpy.org/doc/stable/reference/generated/numpy.select.html ). Importantly, this function also has a `default` argument that lets you determine what value to enter if none of the conditions were met. \n",
    "\n",
    "The following code applies `np.select()` by defining two possible conditions (e.g. a transaction is above the threshold or it isn't) and two corresponding values to enter within our 'large_purchase' column (1 or 0). It also adds a 'default' value of -1; this value will get added to the large_purchase column when a given transaction amount is missing. (Note that, if no default value is specified, numpy will add values of 0--which would easily get mistaken here for the 'not a large purchase' condition.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "561c7366-21d6-499b-8631-b0f8cbf60577",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:26.223046Z",
     "iopub.status.busy": "2025-03-22T17:51:26.222835Z",
     "iopub.status.idle": "2025-03-22T17:51:26.228319Z",
     "shell.execute_reply": "2025-03-22T17:51:26.228078Z",
     "shell.execute_reply.started": "2025-03-22T17:51:26.223035Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starting_year</th>\n",
       "      <th>level</th>\n",
       "      <th>amount</th>\n",
       "      <th>large_purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>Fr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>Se</td>\n",
       "      <td>12.22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>Se</td>\n",
       "      <td>23.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>Fr</td>\n",
       "      <td>18.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22449</th>\n",
       "      <td>2023</td>\n",
       "      <td>Fr</td>\n",
       "      <td>5.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22450</th>\n",
       "      <td>2023</td>\n",
       "      <td>So</td>\n",
       "      <td>7.39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22451</th>\n",
       "      <td>2023</td>\n",
       "      <td>Fr</td>\n",
       "      <td>13.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22452</th>\n",
       "      <td>2023</td>\n",
       "      <td>Fr</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22453 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       starting_year level  amount  large_purchase\n",
       "0               2023    Fr     NaN              -1\n",
       "1               2023    Se   12.22               0\n",
       "2               2023    Se   23.10               0\n",
       "3               2023    Fr   18.78               0\n",
       "...              ...   ...     ...             ...\n",
       "22449           2023    Fr    5.98               0\n",
       "22450           2023    So    7.39               0\n",
       "22451           2023    Fr   13.25               0\n",
       "22452           2023    Fr    1.95               0\n",
       "\n",
       "[22453 rows x 4 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condlist = [\n",
    "    df_transactions_faulty['amount'] >= large_purchase_threshold,\n",
    "    df_transactions_faulty['amount'] <= large_purchase_threshold\n",
    "]\n",
    "\n",
    "choicelist = [1,\n",
    "              0] # Make sure that the order of these entries matches\n",
    "# that of your condlist entries!\n",
    "\n",
    "df_transactions_faulty['large_purchase'] = np.select(\n",
    "    condlist, choicelist, default=-1)\n",
    "df_transactions_faulty   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dc6483-faeb-4bb5-9169-4daa43646fac",
   "metadata": {},
   "source": [
    "Now that we've added in this column, we can create a pivot table that shows the likelihood, for each level, that a given transaction was at or above the 90th percentile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "55e361fb-13e0-42c6-a583-4caef650b47d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T17:51:26.228878Z",
     "iopub.status.busy": "2025-03-22T17:51:26.228650Z",
     "iopub.status.idle": "2025-03-22T17:51:26.265313Z",
     "shell.execute_reply": "2025-03-22T17:51:26.265076Z",
     "shell.execute_reply.started": "2025-03-22T17:51:26.228867Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>large_purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fr</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ju</td>\n",
       "      <td>0.297705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Se</td>\n",
       "      <td>0.434444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So</td>\n",
       "      <td>0.081307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  level  large_purchase\n",
       "0    Fr        0.000000\n",
       "1    Ju        0.297705\n",
       "2    Se        0.434444\n",
       "3    So        0.081307"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions_faulty.query(\"large_purchase != -1\").pivot_table(\n",
    "    index = 'level', \n",
    "    values = 'large_purchase', aggfunc = 'mean').reset_index()\n",
    "                                   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010d8606-d0d4-4103-96c7-9ddcacda72dc",
   "metadata": {},
   "source": [
    "This likelihood is evidently much higher for upperclassmen (juniors and seniors) than for underclassmen (freshmen and sophomores). Of course, this analysis isn't perfect, as it's limited to the rows for which we have valid transaction amounts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e3f403-d074-4363-893c-a328a7b3667e",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edadb494-55b6-4edf-935d-9b54968df757",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-22T16:30:10.428839Z",
     "iopub.status.busy": "2025-03-22T16:30:10.428458Z",
     "iopub.status.idle": "2025-03-22T16:30:10.437165Z",
     "shell.execute_reply": "2025-03-22T16:30:10.436746Z",
     "shell.execute_reply.started": "2025-03-22T16:30:10.428825Z"
    }
   },
   "source": [
    "These two chapters have offered a brief introduction--and certainly not a comprehensive reference--to the use of Pandas to calculate descriptive statistics within Python. My hope is that, now that you've seen how easily Pandas can perform various statistical calculations, you'll be inspired to test this library out for other tasks as well.\n",
    "\n",
    "I have found in my own work that, while descriptive stats are less 'trendy' than more recent developments in the field of statistics (e.g. machine learning, neural networks, etc.), they're still incredibly useful as a way to share, both internally and externally, how your nonprofit is performing and how those whom it serves are doing. These kinds of descriptive analyses will also serve as the foundation for many different visualizations, as we'll see later in Python for Nonprofits.\n",
    "\n",
    "Now that we've learned how to retrieve, reformat, and analyze data, we can move on to a task (importing Census data) that applies each of these skills."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
