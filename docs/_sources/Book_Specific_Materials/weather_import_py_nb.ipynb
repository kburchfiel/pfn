{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d27a197-b7c4-4e4b-85fb-2e94cbbd07ca",
   "metadata": {},
   "source": [
    "# weather_import.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e8273af-0ab3-4b04-8dc7-f7a6c42dd285",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T05:04:21.417556Z",
     "iopub.status.busy": "2025-01-09T05:04:21.416558Z",
     "iopub.status.idle": "2025-01-09T05:04:21.613076Z",
     "shell.execute_reply": "2025-01-09T05:04:21.612730Z",
     "shell.execute_reply.started": "2025-01-09T05:04:21.417485Z"
    }
   },
   "outputs": [],
   "source": [
    "# Weather Import\n",
    "# By Kenneth Burchfiel\n",
    "# Released under the MIT license\n",
    "\n",
    "# This file contains a function that performs the data retrieval \n",
    "# steps deliniated in recent_weather_data.ipynb within\n",
    "# the Automated_Notebooks section of Python for Nonprofits.\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def weather_import(station_code, data_folder = ''):\n",
    "    '''This function retrieves NWS hourly weather data for the last \n",
    "    3 days for the station specified in station_code; adds it to\n",
    "    pre-existing data (if any); and then saves this data to\n",
    "    the folder specified in data_folder. \n",
    "    (Specifying a data folder is optional; if none is specified, files\n",
    "    will simply be saved to the current working directory.)'''\n",
    "    if len(data_folder) > 0:\n",
    "        post_folder_char = '/'\n",
    "    else:\n",
    "        post_folder_char = ''\n",
    "    today = datetime.today().date()\n",
    "    retrieval_date = str(today) # The date that the current set of 3-day\n",
    "    # weather history data is being retrieved. Note that this date won't\n",
    "    # match the dates for earlier records within this dataset.\n",
    "    # Importing the latest set of hourly observations from the \n",
    "    # National Weather Service:\n",
    "\n",
    "    # read_html returns a list of tables (even though only one table is \n",
    "    # currently present on this site), so we'll use [0] to access that\n",
    "    # table.\n",
    "    # The final 3 rows are simply a repetition of the header, so I added in\n",
    "    # [:-3] to exclude them from the DataFrame.\n",
    "    # header = 2 specifies that the third row in the DataFrame should be \n",
    "    # used as a header. (The first two rows' values are mostly duplicates\n",
    "    # of this row's data.)\n",
    "\n",
    "    \n",
    "    df_3day_data = pd.read_html(\n",
    "    f'https://forecast.weather.gov/data/obhistory/{station_code}.html',\n",
    "    header = 2)[0][:-3]\n",
    "    df_3day_data.tail()\n",
    "\n",
    "    # The observation time column within this dataset shows the time zone; \n",
    "    # this will cause issues when daylight savings time begins or ends \n",
    "    # (as those events will cause the column name to change). To prevent \n",
    "    # this from causing any issues when combining our latest data with \n",
    "    # our historical dataset, we'll add this time zone data to a \n",
    "    # separate column, then rename the original time column to 'Time.'\n",
    "\n",
    "    original_time_col = [\n",
    "        column for column in df_3day_data.columns if 'Time' in column][0]\n",
    "\n",
    "    tz = original_time_col.split(' (')[1].split(')')[0].upper()\n",
    "\n",
    "    df_3day_data.rename(columns={original_time_col:'Time', 'Date':'Day'}, \n",
    "                        inplace = True)\n",
    "    df_3day_data.insert(2, 'Time Zone', tz)\n",
    "    df_3day_data['Day'] = df_3day_data['Day'].astype('int')\n",
    "    df_3day_data['Data Retrieval Date'] = pd.to_datetime(\n",
    "        datetime.today().date())\n",
    "    \n",
    "    ## Determining the year and month of each observation:\n",
    "    \n",
    "    # The original NWS dataset only shows the day of the month for each row \n",
    "    # (which is understandable, since it only contains data for the most \n",
    "    # recent 72 hours; thus, the year and month can easily be inferred). \n",
    "    # However, because we'll be keeping a historical copy of this data, \n",
    "    # calculating each observation's corresponding year and month will \n",
    "    # be crucial for avoiding ambiguous results.\n",
    "    \n",
    "    # We'll use the following approach to generate a YYYY-MM-DD-formatted \n",
    "    # 'Date' column for each observation:\n",
    "    \n",
    "    # 1. We'll use the year and month found within our Data Retrieval Date \n",
    "    # column as a basis for our observation years and months.\n",
    "    \n",
    "    # 2. If the observation day is less than the day within our Data \n",
    "    # Retrieval Date column, we'll assume that that observation took place \n",
    "    # within the current month; otherwise, we'll assume it took place \n",
    "    # during the previous month and thus reduce the observation month \n",
    "    # by 1. (For instance, an observation day of 5 and a data retrieval \n",
    "    # day of 6 would indicate that the observation and data retrieval \n",
    "    # months are the same; meanwhile, an observation day of 31 and a data\n",
    "    # retrieval day of 2 demonstrates that the observation took place \n",
    "    # during the previous month.)\n",
    "    \n",
    "    # 3. The previous step will result in an observation month of 0 if \n",
    "    # data for December were retrieved in January. In this case, we'll \n",
    "    # decrease the observation year by 1 and switch the observation \n",
    "    # month to 12. Otherwise, we'll use the data retrieval year \n",
    "    # as our observation year.\n",
    "    \n",
    "    # 4. Finally, we'll add these observation month and years to the \n",
    "    # pre-existing observation day column in order to produce a new \n",
    "    # 'Date' column in YYYY-MM-DD format.\n",
    "\n",
    "    df_3day_data['Data Retrieval Date'] = pd.to_datetime(\n",
    "        df_3day_data['Data Retrieval Date'])\n",
    "    \n",
    "    df_3day_data['Obs_Month'] = np.where(\n",
    "        df_3day_data['Day'] <= df_3day_data['Data Retrieval Date'].dt.day, \n",
    "        df_3day_data['Data Retrieval Date'].dt.month, \n",
    "        df_3day_data['Data Retrieval Date'].dt.month -1)\n",
    "    \n",
    "    df_3day_data['Obs_Year'] = np.where(\n",
    "        df_3day_data['Obs_Month'] != 0,\n",
    "        df_3day_data['Data Retrieval Date'].dt.year, \n",
    "        df_3day_data['Data Retrieval Date'].dt.year-1)\n",
    "    \n",
    "    df_3day_data['Obs_Month'] = df_3day_data['Obs_Month'].replace(\n",
    "        0, 12).copy()\n",
    "    \n",
    "    # Creating our Date column:\n",
    "    # Note the use of str.zfill() to add a leading 0 to single-digit\n",
    "    # months and dates (which will make it easier to sort them in \n",
    "    # chronological order).\n",
    "    df_3day_data.insert(0, 'Date', (\n",
    "        df_3day_data['Obs_Year'].astype('str') + '-' +\n",
    "        df_3day_data['Obs_Month'].astype('str').str.zfill(2) + '-' +\n",
    "        df_3day_data['Day'].astype('str').str.zfill(2)))\n",
    "    \n",
    "    # Sorting the dataset chronologically:\n",
    "    df_3day_data.sort_values(['Date', 'Time'], inplace = True)\n",
    "    df_3day_data\n",
    "\n",
    "    # Saving this data to a .csv file:\n",
    "    df_3day_data.to_csv(\n",
    "        f'{data_folder}{post_folder_char}{station_code}\\\n",
    "_most_recent_3_day_data.csv', \n",
    "        index = False)\n",
    "\n",
    "    # Appending new data within this file to our historical dataset:\n",
    "\n",
    "    # Creating a historical copy of the 3-day dataset for the weather \n",
    "    # station being evaluated if one does not exist already:\n",
    "    # Determining which argument to pass to os.listdir(): (This argument\n",
    "    # should be None if no data folder was provided so as not to raise\n",
    "    # an error.)\n",
    "    if len(data_folder) > 0:\n",
    "        listdir_arg = data_folder\n",
    "    else:\n",
    "        listdir_arg = None\n",
    "    if f'{station_code}_historical_hourly_data.csv' not in os.listdir(\n",
    "        listdir_arg):\n",
    "        \n",
    "        print(\"Historical copy of this dataset doesn't yet exist. \\\n",
    "Initializing it as a copy of the 3-day dataset.\")\n",
    "        df_3day_data.to_csv(\n",
    "            f'{data_folder}{post_folder_char}{station_code}\\\n",
    "_historical_hourly_data.csv', index = False)\n",
    "              \n",
    "\n",
    "    \n",
    "    df_historical_data = pd.read_csv(\n",
    "        f'{data_folder}{post_folder_char}\\\n",
    "{station_code}_historical_hourly_data.csv')   \n",
    "    print(\"Original length of historical data file:\",\n",
    "          len(df_historical_data))\n",
    "    \n",
    "    # Recreating df_3day_data by importing the .csv copy of the table \n",
    "    # that we just created:\n",
    "    \n",
    "    # (This step may appear unnecessary, but it does help ensure that \n",
    "    #  both this data and that found in df_historical_data will use \n",
    "    #  the same data types.)\n",
    "\n",
    "    df_3day_data = pd.read_csv(f'{data_folder}{post_folder_char}\\\n",
    "{station_code}_most_recent_3_day_data.csv')\n",
    "\n",
    "    # Combining our previous historical data with our latest dataset \n",
    "    # from the last 3 days:\n",
    "    \n",
    "    df_wx = pd.concat([df_historical_data, df_3day_data])\n",
    "    # Storing the station code within the DataFrame:\n",
    "    df_wx['Station'] = station_code\n",
    "    # Removing duplicate Date/Time entries:\n",
    "    \n",
    "    # Calculating the 24-digit hour corresponding to each DataFrame:\n",
    "    # (This code assumes that a 24-hour clock is being used to display\n",
    "    # times.)\n",
    "    df_wx['Hour'] = df_wx['Time'].str.split(\n",
    "        ':').str[0].astype('int')\n",
    "\n",
    "    # Keeping only one result per date and hour:\n",
    "    # (This approach will prove useful when using .rolling() to calculate\n",
    "    # rainfall totals for specific periods, as it will allow us to\n",
    "    # assume that N rows of data represent N hours. However, \n",
    "    # at least one NWS station (KOKV) reports recent weather data\n",
    "    # every 20 minutes; only one in three of such reports will get\n",
    "    # retained after drop_duplicates() gets called. \n",
    "    df_wx.drop_duplicates(\n",
    "        ['Date', 'Hour'], keep = 'last', inplace = True)\n",
    "    # This isn't a perfect approach, as it will likely cause an \n",
    "    # hour of data to get lost when Daylight Savings Time ends.\n",
    "     \n",
    "    print(\"New length of historical data file:\",\n",
    "          len(df_wx))\n",
    "\n",
    "    # Saving this updated copy of df_wx to a .csv file:\n",
    "    df_wx.to_csv(\n",
    "        f'{data_folder}{post_folder_char}\\\n",
    "{station_code}_historical_hourly_data.csv', index = False)\n",
    "\n",
    "    ## Making further updates to this combined dataset:\n",
    "\n",
    "    # Removing percentages from Relative Humidity column so that these\n",
    "    # values can be converted to floats:\n",
    "    \n",
    "    df_wx['Relative Humidity'] = df_wx[\n",
    "    'Relative Humidity'].str.replace('%','')\n",
    "    \n",
    "    # Converting numerical data in certain columns to floats:\n",
    "    \n",
    "    for column in ['Air', 'Dwpt', 'altimeter (in)', 'sea level (mb)',\n",
    "                   '1 hr', '3 hr', '6 hr', 'Relative Humidity']:\n",
    "        df_wx[column] = df_wx[column].astype(\n",
    "            'float')\n",
    "    \n",
    "    # Replacing NaN precipitation values with 0s:\n",
    "    for column in ['1 hr', '3 hr', '6 hr']:\n",
    "        df_wx[column] = df_wx[\n",
    "        column].fillna(0).copy()\n",
    "    \n",
    "    df_wx.tail()\n",
    "    \n",
    "    # Adding 'Precip' prefixes to the hourly precipitation rows; making the \n",
    "    # temperature and dew point column names more intuitive; and removing\n",
    "    # time zone data from the Time field:\n",
    "    df_wx.rename(columns = {\n",
    "        '1 hr':'1-Hour Precip',\n",
    "        '3 hr':'3-Hour Precip',\n",
    "        '6 hr':'6-Hour Precip',\n",
    "        'Air':'Temp',\n",
    "        'Dwpt':'Dew Point',\n",
    "        'altimeter (in)':'Altimeter (in.)',\n",
    "    original_time_col:'Time'},\n",
    "         inplace = True)\n",
    "    \n",
    "    # Sorting the table in chronological order so that our charts will\n",
    "    # be easier to interpret:\n",
    "    \n",
    "    df_wx.sort_values(['Date', 'Time'], inplace = True)\n",
    "    df_wx.reset_index(drop=True,inplace=True)\n",
    "\n",
    "    # Adding columns that show cumulative precipitation totals for various\n",
    "    # periods: (These all update every hour unlike the built-in\n",
    "    # NWS hourly precipitation totals. However, they're also \n",
    "    # susceptible to errors caused by missing rows.)\n",
    "    for hourly_interval in [3, 6, 12, 24]:\n",
    "        df_wx[f'Rolling {hourly_interval}-Hour Precip'] = (\n",
    "            df_wx['1-Hour Precip'].rolling(\n",
    "                window=hourly_interval).sum())\n",
    "\n",
    "    # Adding a windspeed column:\n",
    "    # This code assumes that the 'Wind (mph)' column within the original\n",
    "    # dataset uses the following formats:\n",
    "    # 'Calm' (when no wind was reported)\n",
    "    # DIRECTION WINDSPEED (e.g. 'W 8') when wind, but no gusts, were\n",
    "    # reported\n",
    "    # DIRECTION WINDSPEED GUST_DIRECTION GUST_SPEED (e.g. 'W 28 G 40')\n",
    "    # when both wind and gusts were reported\n",
    "    # The following code uses str.split() and str[1] to retrieve the \n",
    "    # second item within these reports, as this item should always be\n",
    "    # the windspeed (rather than the gust speed). \n",
    "    \n",
    "    df_wx['Windspeed'] = df_wx['Wind (mph)'].str.split('  ').str[\n",
    "    1]\n",
    "\n",
    "    # For 'Calm' readings,\n",
    "    # str[1] will be NaN, and thus we can replace those values with 0.\n",
    "\n",
    "    df_wx['Windspeed'] = np.where(df_wx['Wind (mph)'] == 'Calm',\n",
    "                                  0, df_wx['Windspeed'])\n",
    "    \n",
    "    # Removing the 6-hour max and min temperature columns in order to \n",
    "    # simplify the table:\n",
    "    df_wx.drop(['Max.', 'Min.'], axis = 1, inplace = True)\n",
    "        \n",
    "    # Creating a 'Date/Time' column for graphing purposes:\n",
    "    \n",
    "    df_wx.insert(\n",
    "        2, 'Date/Time', df_wx['Date'].astype('str') \n",
    "        + ' ' + df_wx['Time'].astype('str'))\n",
    "    \n",
    "    df_wx.tail()\n",
    "\n",
    "    # Saving this revised dataset to a .csv file so that it can be \n",
    "    # visualized and shared with others:\n",
    "\n",
    "    df_wx.to_csv(f'{data_folder}{post_folder_char}\\\n",
    "{station_code}_historical_hourly_data_updated.csv', index = False)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
